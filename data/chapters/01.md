## CHAPTER 1 The nature of science

### 1.1 SCIENTIFIC KNOWLEDGE OF CLIMATE CHANGE

After reading this section, you should be able to:

- Explain why climate change is a serious practical concern
- Describe how scientific research supports the finding of human‐caused climate change and why public opinion lags behind the research
- List three indicators that scientific knowledge is trustworthy

#### A serious practical concern

In November 2023, the 28th United Nations Climate Change conference was held in the United Arab Emirates. This event was the 28th Conference of the Parties (COP28) to the United Nations Framework Convention on Climate Change (UNFCCC). COP28 was also the 18th meeting of the parties to the Kyoto Protocol, which in 1997 extended and expanded the nations supporting the UNFCCC, and the fifth meeting of the parties to the Paris Agreement, signed by 196 countries in 2015. As this book was printed, COP29 was in planning for November 2024, and annual international meetings in this series are intended to continue.

International conferences about the challenge of climate change have been occurring for 30 years, with increasing consensus about the measures needed to counteract rising global temperatures. A primary goal is to limit the rise in global mean temperature—the average of all land and ocean surface temperatures—to 1.5° Celsius or below compared to preindustrial levels. This temperature change would be minor if it were a single‐day temperature in one place. But a 1.5° Celsius increase in global mean temperature is a major change with radical consequences.

Think of this temperature increase like a fever. The human body maintains a relatively constant temperature in the range of 36.5°–37.5° Celsius (97.7°–99.5° Fahrenheit). When your body temperature increases 1.5° Celsius, which is nearly 3° Fahrenheit, you have a fever. If your body were suddenly that much warmer on average, day in and day out for months and years, it would be a serious medical emergency.

An average global temperature increase of 1.5° Celsius would be similarly devastating for Earth. But why? First, because it changes the Earth’s climate.

Climate change, mountain glaciers are shrinking, and ice sheets are melting in the Arctic, Greenland, and Antarctica. These changes lead to sea levels rising, thereby flooding coastal areas. Precipitation patterns across seasons also become more unstable, leading to more droughts, heat waves, flooding from storms, and wildfires—even shifting the growth timing of plants and crops that makes them more vulnerable to loss.

Second, the changing climate has downstream effects. These effects threaten to push some animal and plant species to extinction, and even collapse ecosystems. Also threatened are human social conditions. Drinking water is scarcer and droughts more frequent or severe; crop yields are expected to decrease. Coastal cities and island nations are at risk of serious floods and devastating hurricanes. All of this affects global health, poverty, hunger, and national security. The World Bank estimates that 200 million people will be forced to migrate between 2020 and 2050 due to the impacts of climate change. Ultimately, global warming will make the Earth less hospitable for all creatures, including humans, and a more unjust place in virtue of who will suffer and how this suffering will be managed. International climate change work therefore includes not just efforts to mitigate climate change but also, increasingly, attention to how to adapt human societies to a changed climate.

Greenhouse gases work like a blanket. As incoming radiation from the Sun permeates our atmosphere, some hits the Earth and is reflected back out to space. But greenhouse gases, such as methane (CH4), carbon dioxide (CO2), and water vapor, trap some of the heat in the atmosphere. This trapped heat warms the planet’s surface, making it hospitable to life. Higher concentrations of greenhouse gases lead to a warmer planet; lower concentrations lead to a cooler planet.

Changing atmospheric concentrations of greenhouse gases are a major factor in Earth’s climate. Other factors include variations in the Earth’s orbit, the motion of tectonic plates, the impact of meteorites, and volcanism on the Earth’s surface. So, our climate has never been static: it has been fluctuating for billions of years. What’s special about the current climate changes, then? Why is this time different?

What’s different is that human activities have led to extreme changes. Since the beginning of the Industrial Revolution, human activities that burn fossil fuels like coal and oil have resulted in carbon dioxide being released into the atmosphere at unprecedented rates. Since carbon dioxide is a greenhouse gas, this increases the heat retention of our atmosphere. Other human activities—primarily agricultural activities such as raising livestock—release methane, which is another greenhouse gas even more potent than carbon dioxide in trapping heat. These human-caused greenhouse gas emissions are so extreme that they’ve led to a historically unprecedented increase in the Earth’s global mean temperature.

This discovery isn’t recent. Scientists have known since the 18th century that burning carbon-based fossil fuels releases carbon into the atmosphere. Systematic research on the relationship between carbon dioxide emissions and climate change began in the 19th century, when the American engineer Marsden Manson discovered how the heat-trapping power of the atmosphere varies with only slight changes in its makeup. A few years later, the Swedish physicist and chemist Svante August Arrhenius completed calculations showing that changes in carbon dioxide also function as a “throttle.” on other greenhouse gases like water vapor. He calculated that there would be an arctic temperature increase of approximately 8° C (46.4° F) from atmospheric carbon levels two to three times their known value at the time. In 1908, Arrhenius predicted, “the slight percentage of carbonic acid in the atmosphere may, by the advances of industry, be changed to a noticeable degree in the course of a few centuries.”

Just before the outbreak of World War II, the British steam engineer Guy Callendar presented a paper to the Royal Meteorological Society, in which he pointed out that the atmospheric concentration of carbon dioxide had significantly increased between 1900 and 1935, based on temperature measurements at 200 meteorological stations. In 1939, Callendar concluded:

As man is now changing the composition of the atmosphere at a rate which must be very exceptional on the geological time scale, it is natural to seek for the probable effects of such a change. From the best laboratory observations it appears that the principal result of increasing atmospheric carbon dioxide . . . would be a gradual increase in the mean temperature of the colder regions of the earth.



This prescient recognition of the role of human activity on atmospheric temperatures had to wait several decades to become widely accepted.

In 1958, the geochemist Charles David Keeling installed four infrared gas analyzers at the Mauna Loa Observatory in Hawai’i. Measurement collection has occurred continuously since 1958, recording an ever-increasing atmospheric CO2 concentration. The graph showing these measurements is known as the Keeling Curve (see Figure 1.2 a).

Keeling’s measurements provided evidence of rapidly increasing carbon dioxide levels in the atmosphere, and a 1979 report by the National Research Council—an American nonprofit organization devoted to scientific research—connected this increase to rise in average temperature. This report predicted that doubling atmospheric CO2 concentration from 300 to 600 ppm would result in an average warming of 2.0°–3.5° C. (Parts per million refers to a unit for measuring small concentrations of a substance.)

We haven’t yet reached the ominous level of 600 ppm, but we’re now long past safe levels of CO2 in the atmosphere, estimated to be about 350 ppm.

 

 Unprecedented increases in atmospheric carbon dioxide after the Industrial Revolution



For several decades, climate scientists have tracked changing atmospheric carbon dioxide levels with increasing precision. Ice cores taken from various locations in the Antarctic have enabled scientists to extrapolate historic CO2 levels for comparison to recent levels (see Figure 1.2(b)). A group of 78 scientists gathered data from several “climate proxies,” including tree rings, pollen, corals, glacier ice, lake and marine sediments, and historical documents. These data provided multiple types of evidence supporting the conclusion that, at the end of the 20th century, atmospheric levels of CO2 and global mean temperature are higher than at any point in the previous 2,000 years.

For the past 800,000 years, atmospheric carbon dioxide hadn’t been over 300 ppm (see Figure 1.3). Since the Industrial Revolution began about 250 years ago, the concentration has spiked to 420 ppm. This is nearly 50% more than levels had reached in 800 millennia—reached in only a quarter of one millennium of human-caused change. (See www.co2.earth for an updated estimate; unfortunately, this number is still climbing steadily.) The last time CO2 levels were this high, humans did not yet exist. In 2022, global mean temperature was 1.06° C (1.90° F) warmer than the pre-industrial period (1880–1900) and has been going up 0.18° C each decade. At this rate, 1.5° C will be surpassed before 2040.

#### Trustworthy scientific knowledge

Centuries of scientific research—including convergence of many types of evidence and broad consensus among scientists with relevant expertise—support the conclusion that we face an unprecedented climate crisis caused by human activity, sometimes called anthropogenic climate change. Like other scientific knowledge, it wasn’t initially obvious and still might not be obvious to those without relevant expertise. Scientists had to try out various techniques and gather different kinds of data to discover this conclusion is true.

Fundamentally, science aims to produce knowledge—in particular, scientific knowledge: explanatory knowledge of why or how the world is the way it is. And it’s the best approach we humans have developed for answering questions about the world around—and within—us. As we will see throughout the book, the scientific establishment has developed countless techniques to acquire knowledge. (You’ve already read about some of these at work in the climate science just described.) Understanding how scientists acquire new knowledge can give people greater reason to trust scientific knowledge, even if they themselves don’t have a full understanding of the evidence, methods, and reasoning leading to it.

First, relevant expertise is important for scientific knowledge to be trustworthy. You should trust climate scientists to do climate science in the same way you trust your mechanic with your car or your favorite restaurant with your dinner. The types of expertise required for these positions takes years, even decades, to develop. But the expertise doesn’t neatly transfer from one domain to another: don’t trust the average climate scientist to fix your car or make you a delicious meal. Similarly, politicians and policymakers know things about political and legislative matters, but they should not be looked to as authorities on the science of climate change—regardless of whether they accept its existence. To do so would be an appeal to irrelevant authority: appealing to the views of an individual who has no expertise in a field as evidence for some claim.

Second, consensus among the relevant experts is an important indicator that the findings are settled scientific knowledge. There is striking agreement among climate scientists about the existence of anthropogenic climate change. Reputable scientists and scientific societies, including the national science academies of the world and the Intergovernmental Panel on Climate Change (IPCC), agree that human-caused, or anthropogenic, climate change is occurring. This includes virtually all climatologists. In 2004, the historian of science Naomi Oreskes analyzed 928 abstracts on climate change published in scientific journals from 1993 to 2003; none expressed disagreement with the consensus position that anthropogenic climate change is occurring. In 2010, a group of researchers studied the views of the 200 climate scientists with the most extensive and productive publication records; more than 97% affirmed the existence of anthropogenic climate change as described by the IPCC.

Third, the convergence of different sources and types of evidence provides solid grounding for scientific knowledge. Well-established theories in physics explain how heat radiation works. Physical chemistry shows how carbon dioxide and other greenhouse gases in the atmosphere traps heat. Climatologists have developed extensive sources of evidence that support the same conclusions about climate change and its relationship to greenhouse gases and human activities. As we described earlier, some of this knowledge goes back centuries, and a range of techniques have been used to amass ever-more relevant evidence. Since the 1950s, scientific models and computer simulations have helped scientists to make testable predictions about what would happen to the global climate in response to different changes in human activities, and evidence has confirmed those predictions.

And yet, despite decisive scientific evidence supporting a consensus among scientists, public concern for climate change lags behind the research. According to surveys from the Pew Research Center from 2013, 44% surveyed across 23 countries did not view climate change to be a major threat; by 2018, that number had dropped to 33% across the same countries. Whether people are concerned about climate change largely

Today’s decisions determine the extent of climate change by 2100 depends on understanding its human causes and level of education. In some countries like the United States, however, being better educated doesn’t predict climate change concern as well as political views do.

People who don’t know much about a given topic can experience an illusion of understanding, in which they lack genuine understanding and so fail to appreciate the depth of their ignorance about that topic. For climate change, this means that people without advanced education in science—a demographic that includes most politicians—tend to have unwarranted confidence in their ability to assess the scientific findings. This includes those who are concerned about climate change as well as those who deny its existence. Worse, illusions of understanding have become easier to sustain in today’s society. Finding information merely through internet searches (so-called Google-knowing) has diminished genuine understanding, and we have limited opportunities for truly public discourse. Our online and in-person conversations tend to happen with people who have beliefs similar to our own.

Improving public climate literacy can support public engagement about global warming. If one knows that Earth is warming up and genuinely understands why, this can lead to changed behavior—for instance, petitioning one’s government to support more energy-efficient practices. More generally, understanding the processes that support trustworthy scientific knowledge—including relevant expertise, broad consensus, and extensive convergent evidence—is vitally important to assessing whether something qualifies as legitimate scientific knowledge and how to go about finding out.

#### EXERCISES

1.1 Recall: How do scientists know that human activities are radically altering Earth’s climate? Why are these changes a serious concern?

1.2 Think: Do all scientists, in virtue of being scientists, have the expertise to make pronouncements about global warming? Or only just those scientists who specialize in the climate sciences? Give reasons to support your answer.

1.3 Think: Describe how a nonspecialist can know whether to trust someone claiming scientific expertise, listing at least three kinds of evidence of their expertise.

1.4 Recall: Identify three indicators that scientific knowledge is trustworthy described in this section. For each, briefly say why it is important.

1.5 Apply: Think of a scientific finding that strikes you as surprising or possibly wrong. Do a little internet research (trying to focus on reputable sources). Assess how that scientific finding fares according to the three indicators that scientific knowledge is trustworthy. Based on this, do you think the finding qualifies as settled knowledge at this stage?

1.6 Think: List three reasons why public concern about anthropogenic climate change lags behind scientific research. Given that lag, how should climate scientists affect environmental policy in the government? Should they merely collect evidence and produce knowledge, leaving policy decisions to public officials? Do they have any obligations to more actively engage with the public?

### 1.2 SUBJECT MATTER AND METHODS

After reading this section, you should be able to:

- Describe what it means for science to provide natural explanations of natural phenomena
- Define empirical investigation and evidentialism and state their importance for science
- Indicate the differences between falsificationism, falsifiability, and openness to falsification, and state which are essential to the nature of science

#### The subject matter of science

We just described some of the abundant scientific evidence for anthropogenic climate change that has amassed over centuries. But we also noted how other experts, including political leaders, have roles to play in public conversations and policy decisions bearing on climate change mitigation and adaptation. What, if anything, is the difference between these forms of expertise?

This question relates to the nature of science, that is, the orientation, values, and methods that are specific to science and allow it to generate knowledge in the ways that it does. To begin, notice that things are more complicated than just saying science is in the business of generating knowledge. Scientific projects can be directed at a wide range of goals. Some scientific research aims at knowledge for its own sake; this is sometimes called basic research. For example, scientists investigate the conditions under which rainbows form to learn more about the behavior of light. Such knowledge may have applications, but basic research is not primarily focused on identifying or developing applications. Instead, basic research often aims for explanatory knowledge: sufficiently justified truths about how things work and why they are the way they are. We know so much about our world, such as how greenhouse gases influence the Earth’s climate, how rainbows form, and how unemployment relates to inflation, because of discoveries and theories generated from basic research.

Yet, science also plays an important role in satisfying practical goals. Many life-changing innovations have come about through computer science. The biological and pharmaceutical sciences have vastly improved medical care and public health. Skyscrapers and airplanes wouldn’t be possible without a lot of physics. The contrast with basic research is applied research. Scientific research is applied when it makes use of scientific knowledge to develop some tangible output, such as techniques, software, drugs, and new materials. Often, a core motivation for applied research is generating products for profit; successful research can result in patentable intellectual property.

Basic and applied scientific research can operate synergistically. Scientists aiming at the production of knowledge for its own sake often rely on materials and techniques created by scientists doing applied research, while scientists doing applied research often exploit pure scientific knowledge in order to develop new products. Still, basic and applied research are often carried out by different scientists, often using very different techniques, and sometimes in entirely different fields of science and types of institutions. For example, when Kathleen Montagu and Arvid Carlsson discovered the neurotransmitter dopamine in the human brain in 1957, this was basic research conducted in a hospital laboratory. In contrast, scientists employed by pharmaceutical companies to develop and improve dopamine-related treatments for Parkinson’s disease are doing applied research.

Beyond this distinction between basic and applied research, there is also tremendous variety in topics among the various fields of science. Investigations range from sub-atomic particles like quarks, to DNA, to emotions, consciousness, and mental maladies, to languages, societies, and economic phenomena, and much else besides. It can seem as if there is a science of absolutely everything! Professional sports are a good example; some scientists devote their research to learning how to improve athletic performance. Other topics of scientific research are more abstract. String theory, for example, is highly theoretical physics that posits one-dimensional entities called strings as the basic building block of our universe.

Despite this variety, it’s possible to give a unifying description of the sort of explanatory knowledge sought in science: science provides natural explanations of natural phenomena. This thesis is sometimes called naturalism.

Natural phenomena are objects, events, or processes that are sufficiently uniform to be susceptible to systematic study. Disease epidemics, lunar eclipses, and droughts are all natural phenomena. Inflation, poverty, and unemployment are all phenomena in human societies, but they also count as natural phenomena under this definition. The word phenomenon (plural phenomena) comes from Greek and means “that which appears or is seen.” So, phenomena include all observable occurrences, that is, occurrences detectable with the use of our senses, including the use of our senses aided by technological devices like telescopes that extend their reach. Natural phenomena need to be somewhat uniform to enable systematic study. Occurring in a regular way is needed for scientists’ observations across different times and places to be used to generate knowledge.

Natural explanations of natural phenomena invoke features of the world—that is, other natural phenomena—to account for these observable occurrences. If there’s an epidemic in France or increased employment in Colombia, you might wonder how that came to be. A natural explanation of the epidemic might specify a contagion and a mechanism of transmission, for example, while a natural explanation for the increase in employment might specify private investments in industry and legislative choices made by political parties. These are both natural explanations of natural phenomena.

Science is always naturalistic in what it investigates and how it explains. The meaning of the term natural in the context of the naturalism of science can be better understood by contrasting it with supernatural. Supernatural entities and occurrences may not be governed by discernible regularities, may not be observable at all or not observable by other people, or are just supposed to transcend the range of physical human experience. Because supernatural entities or occurrences are not natural phenomena, science won’t be able to deliver knowledge about them: they would be beyond its explanatory reach. Nor does science appeal to supernatural entities or occurrences to explain natural phenomena. “A miracle caused her to recover from disease” couldn’t possibly be a scientific explanation, even though recovering from a disease is a natural phenomenon.

#### The methods of science

Science’s goal of providing natural explanations of natural phenomena isn’t all that is distinctive about the nature of science. Also significant are science’s methods. One important ingredient of these methods is closely related to the idea of naturalism: science involves empirical investigation, which means using one’s senses to inform one’s beliefs about the world. What scientists see, hear, smell, touch, and so forth can all be used as empirical evidence for or against some attempted natural explanation.

The method of empirical investigation isn’t special to science. We all use our senses in everyday life to learn about the world around us, beginning as infants. You know it’s a clear day because you can see and feel the sun shining through the window. But science has fine-tuned and adapted this method to generate certain kinds of knowledge.

In science, empirical investigation is explicitly used to generate evidence. Science is thus based on evidentialism, the thesis that a belief’s justification is determined by how well it is supported by evidence. For any scientific claim—particularly, any natural explanation of a natural phenomenon—it must be possible to state why that claim should be believed. This evidence ultimately traces back to empirical observations, but empirical evidence often confirms scientific claims only indirectly. We don’t directly see human activity increasing atmospheric CO2, for example; rather, scientists made predictions about changes to the atmosphere, historical trends in global temperature, and more, based on this conjecture; and then they tested those predictions with empirical evidence. So, evidentialism is important to science, but how evidence is gathered and used is not always straightforward.

# 

##### Box 1.1 Is science always empirical? 

Scientists typically use empirical evidence as the basis for knowledge. However, in fields like mathematics, computer science, and economics, some claims are not based on empirical evidence, or at least not directly. The mathematical claim that Log2(1/2) = −1 is not an empirical claim, in the sense that it’s not based on observation. Something similar—perhaps surprisingly—applies to physics too, where it can be very hard to obtain empirical evidence that bears on some phenomena. String theory, for example, is the idea that the fundamental objects in the world are extended, one-dimensional objects called strings. Empirical evidence of these strings cannot be provided by present-day instruments, but string theory has been developed to account for features of fundamental physics that are well confirmed empirically, and string theorists work to find nonempirical evidence that bear on this theory. Sources of nonempirical evidence include the simplicity and unifying and explanatory power of a theory, plus the logical relationships between the theory and other claims well confirmed by the empirical evidence or believed to be self-evidently true. Nonempirical evidence in favor of string theory includes that it can account for well-corrob- orated claims in fundamental physics, that it has been productively applied to a range of scientific problems like black holes and nuclear physics, and that it fits with both quantum mechanics and Einstein’s theories of gravity. So, not all evidence is empirical evidence, and not all scientific research is based on empirical evidence.

Evidentialism in science leads to continual, self‐corrective investigation in which ideas are fine‐tuned or extended in light of new evidence. Significant empirical evidence is needed before some scientific claim, like the claim that human activity is causing global warming, is broadly accepted as settled scientific knowledge. There are many scientific findings that are so well supported by evidence that they seem entirely certain. We know atmospheric CO2 is more than 50% higher now than at any other time in human history, and we know that the last four decades are the warmest on record. We know anthropogenic climate change is occurring. We also know that the Earth orbits around the Sun, that water molecules are composed of two hydrogen atoms and one oxygen atom, and so much more. Still, in principle, scientific claims are never taken to be absolutely beyond any doubt. And very occasionally, continuing investigation even leads widely held or long‐established ideas to be significantly revised.

Karl Popper was a philosopher of science in the early 20th century who took this in‐principle revisability of science to be especially important. Popper developed a principle called falsificationism, which names the thesis that scientific reasoning proceeds by attempting to disprove claims rather than to prove them right—that is, by advancing bold and risky conjectures, and then trying to falsify or refute them. This criterion for science has been very influential among scientists, but it is controversial. One problem is that the relationship between empirical evidence and a scientific theory can be complicated, so that it is sometimes hard to say when the evidence would disprove a theory. A second problem is that incessantly trying to prove central claims false would limit scientific progress. It seems scientists do accept theories and hypotheses that are well supported by evidence, moving on to downstream questions based on those theories and hypotheses.

Two other aspects of falsificationism do seem more plausible. First, any scientific claim should in principle be falsifiable. A claim is falsifiable when it is possible to describe what kind of evidence would, if found, show the claim to be false. This property is required for scientific claims to be subject to empirical evidence; without it, a claim would be unscientific. Notice that true claims can be falsifiable—you can describe what kind of evidence would, if found, disprove a true claim. It’s just that, because the claim is true, you will never actually find such evidence. Even for false claims, scientists may never be in the right circumstances to obtain falsifying evidence. Putting forward falsifiable claims enables science to be based on empirical evidence and to reject ideas when the evidence warrants doing so.

Second, science requires honesty when empirical evidence does indicate a claim is false. When scientists discover apparently falsifying evidence, they should begin to doubt the ideas under investigation. In general, we humans try hard to hold on to our existing beliefs, even when those beliefs are challenged. Scientists are no different. But science’s evidentialism requires scientists to doubt any scientific claims—even claims they had thought were really promising—when empirical evidence suggests they may be wrong. We might call this openness to falsification: any claim should be abandoned when the preponderance of evidence indicates that it’s false.

# 


##### EXERCISES

1.7 Recall: Define natural phenomena and natural explanations, and describe the importance of each to science’s ability to generate trustworthy knowledge.

1.8 Apply: Describe one real example of basic research and one real example of applied research. For each, describe your reasoning in considering it basic or applied research.

1.9 Recall: Describe what it means for science to provide natural explanations of natural phenomena. What are the limitations to the kinds of knowledge science can produce due to this requirement?

1.10 Recall: Define empirical investigation and evidentialism. Describe how they are different from each other and how each is important to science.

1.11 Think: Evaluate how and why the subject matter and methods of science are each relevant to the nature of science.

1.12 Recall: Define falsificationism, falsifiability, and openness to falsification, making sure you are clear about how each is different from the others. For each, say whether it is essential to science and why.

### 1.3 THE INSTITUTION OF SCIENCE

After reading this section, you should be able to:

- Define confirmation bias and give examples of how it works
- Describe how social structure is important to the nature of science
- Describe how social norms for individual scientists and the scientific community are important to the trustworthiness of science

#### Flaws in human reasoning

Empirical investigation is a basic aspect of human existence and so not special to science. Why, then, is science needed to give us knowledge about the world, beyond just our ordinary human powers of observation? Just as we humans are predisposed to investigate our world using our senses from our first days of infancy, we are also predisposed to some serious flaws in how we gather evidence and how we reason. Science is the best route to knowledge about the world in part because it incorporates ways to protect against those flaws in reasoning.

It is normal for people to favor some ideas over others. We can then use our experiences in the world, investigation of existing knowledge, and critical thinking to ensure that the ideas we favor are, in fact, good ideas. The problem is, we also seek out and interpret information in ways that fit with our favored ideas, and we avoid information that challenges those ideas. This is a well-established feature of human reasoning called confirmation bias

Confirmation bias: the tendency to look for, interpret, and recall evidence in ways that confirm and do not challenge our existing beliefs.

Imagine someone has just brought her friends to a restaurant she’s selected. When she asks her friends if they like the restaurant, she may say, “It’s good, isn’t it?” Framing the question in this way promotes agreement with the judgment she already has of the restaurant—it’s a way of looking for confirming evidence. Similarly, someone who’s skeptical about climate change may perform an internet search for the phrase evidence against climate change to learn more, or they may focus on what critics say and ignore what climate scientists say. Someone concerned about genetically modified crops is more likely to make time to read an article entitled “Dangers of Genetic Modification” than an article titled “Genetic Modification Boosts Soy and Corn Performance.” These are ways of seeking evidence that confirms one’s existing ideas rather than challenging those ideas. We are also prone to interpreting evidence as supporting our existing ideas. In one study, people who were in favor of and opposed to the death penalty both read the same discussion of the death penalty. People on each side of the issue interpreted the discussion entirely differently; each side thought it supported their own view.

Confirmation bias can involve looking only for evidence that supports your existing beliefs, cherry-picking which research to believe and which to ignore, holding evidence against your views to a higher standard than evidence in favor of your views, and more easily remembering supporting evidence than contrary evidence.

We all do this; it doesn’t matter what views about the world we have, what political views we have, whether we’ve graduated from college, or whether we have been trained as scientists. In fact, some evidence suggests that confirmation bias worsens with increased education. Although everyone is prone to confirmation bias, the effect tends to be stronger for politically or emotionally charged issues, such as vaccinations, climate change, and health.

Scientists’ expectations or desires about the results of scientific research can lead to incorrect findings. One way in which this can happen is through the observer-expectancy effect, when a scientist’s expectations lead them (perhaps, unconsciously) to influence the behavior of experimental subjects. A famous example of this involved Clever Hans, a horse who was thought to have sophisticated abilities including performing arithmetic calculations. Hans’s owner, Wilhelm von Osten, was a mathematics teacher, horse trainer, and phrenologist. (Phrenology is the now-discredited study of the shape of the skull as an indicator of personality and mental abilities.) Hans was trained to recognize numerals from 1 to 9 and to tap his hooves to indicate which ones he recognized. Eventually, van Osten had Hans tapping out correct answers to questions like: what’s the number of 4s in 16?

In 1891, van Osten traveled around Germany to exhibit his amazing horse. There was such fanfare that the famous psychologist Carl Stumpf appointed a special commission to provide critical scrutiny. In 1904, the commission concluded that Hans’s abilities were legitimate. The horse was able to answer questions from simple arithmetic to square roots, fractions and decimals, units of time, musical scales, and the value of coins. Hans could even respond accurately when van Osten wasn’t present.

 

  

FIGURE 1.6
The commission was wrong. Stumpf’s pupil, Oskar Pfungst, demonstrated that Clever Hans was not performing sophisticated mental calculations. Pfungst used blinders to vary whether Hans could see the questioner, and he varied who played the role of questioner. Hans produced the correct answer even when van Osten himself did not ask the questions, but Hans’s performance fell apart when the questioner did not know the answer or when the horse was asked the question from behind a screen. When the visibility of spectators and questioners was masked, Hans’s ability to produce correct answers fell dramatically from 89% to 6%. Further observations confirmed that Hans was being unwittingly cued by his human audience. Questioners’ body language and facial expressions became taut as his tapping approached the correct answer, and then more relaxed upon the final tap; this change prompted Hans to stop tapping.

#### Science as a social enterprise

Like van Osten and all the other people who asked questions of Clever Hans, our expectations can affect how matters play out, even when we don’t intend this to happen. This possibility makes it hard for people—including scientists—to reason their way to the right answers. For this reason, one element of science’s great success in generating knowledge about our world is its institutional features that protect against or counteract the basic flaws in human reasoning.

Scientific research requires communities of many people working together. Teams of scientists work together on research projects; it is common for research publications to have multiple authors. Scientists also regularly make use of techniques, data, or ideas developed by other scientists. And all new scientific research is based in part on the findings of previous scientists. Such collaboration is essential to the development and refinement of scientific knowledge: no one scientist can produce scientific knowledge on their own.

We have seen how science is based on empirical investigation. And yet, empirical evidence bearing on scientific claims often doesn’t come directly from an individual scientist’s own observations. Instead, an important source of evidence is other scientists’ reports of their observations as detailed in research publications. Keeling and his collaborators first measured the increasing concentration of atmospheric CO2 depicted in the Keeling curve, but many more climate scientists later made use of those data in their own research. Scientific collaboration thus greatly amplifies the reach of empirical investigation.

Collaboration and competition among scientists also help detect and correct flaws in human reasoning, giving rise to the self-corrective process of refining scientific knowledge. Collaboration among scientists creates opportunities for people with other viewpoints to analyze the evidence and ideas from their own perspectives and methodologies. While new research projects are based on the findings of previous scientists, they are also opportunities to refine or challenge those earlier findings. Competition among scientists—to make a discovery before anyone else, to get their research projects funded, and to show that an idea is better supported by the evidence than an opposing idea—also spurs reexamination of ideas that other scientists might take for granted. Collaboration and competition in science should combine to increase the trustworthiness of scientific knowledge. If a large and diverse group of scientists agree about some finding, we should be more confident that it is legitimate.

This raises another point about the importance of science as a social enterprise. To adequately protect against individual flaws in reasoning, scientific communities need to be diverse in order to provide satisfactory interpretations of the available evidence, as well as to formulate and test a variety of ideas, including perspectives from different nationalities, races and ethnicities, gender identities, cultures, and more. This kind of diversity benefits science by guarding against any individual biases and personal values.

#### Social norms of science

Because the institutional structure of science is essential to its ability to generate knowledge, science has important social norms—rules or guidelines that scientific activities should adhere to and against which they are evaluated. One set of norms applies to the behavior of scientists. Scientists are obligated to have scientific integrity, which involves expectations of honesty and avoiding improper influence by others. Norms of scientific integrity are so important that their violation is severely punished by the scientific community, such as with bans from publishing in scientific journals or even loss of one’s job as a scientist.

Examples of scientific dishonesty include plagiarism and fabricating data. Plagiarism is the fraudulent theft of someone else’s ideas, scientific results, or words, which are subsequently presented as one’s own work without giving proper credit. Fabricating data occurs when, rather than collecting empirical evidence, scientists create records of observations they didn’t actually make in order to use them as evidence to support a desired conclusion.

In 2011, a Dutch social psychologist, Diederik Stapel, published a widely read study in *Science*, one of the most prestigious scientific journals, presenting evidence that trash-filled environments lead people to be more racist. But rather than collecting actual data, Stapel just made it up. When this was discovered, his reputation immediately collapsed. All his other publications were scrutinized, and approximately 60 other papers were retracted for data fabrication. Other scientists have also been forced out of science after their ethics violations were discovered, such as the Seoul National stem-cell researcher Hwang Woo-suk and the Harvard evolutionary biologist Marc Hauser. Some science journalists have helped increase awareness of issues like plagiarism and data fabrication by running blogs such as Retraction Watch*.

##### Box 1.2 Merton’s social norms of science

Social norms are informal rules that govern behavior in groups and societies. American sociologist of science Robert Merton specified four social norms that govern scientists’ attitudes and behaviors towards each other and their research, thereby enhancing the moral integrity of scientific communities and supporting the expansion of scientific knowledge.

1. Communism: scientific findings and methods are common goods owned by all and should be shared freely.
2. Universalism: scientific work should be evaluated based on impersonal criteria like coherence with other bodies of knowledge and empirical confirmation. In other words, scientific work should be independent of the socio-political or personal status of the scientists involved.
3. Disinterestedness: scientific work should not be aimed at personal gain.
4. Skepticism: scientific work should be scrutinized critically and transparently by relevant scientific communities before being accepted.

These four norms relate to how we are discussing collaboration and competition and social norms of science in this section.

Scientists also are expected to avoid conflicts of interest: financial or personal gains that have the potential to inappropriately influence scientific research, results, or publication. Conflicts of interest, especially when research is funded by organizations with a financial stake in the findings, can result in researchers intentionally or unintentionally altering what research they conduct, their findings, or what they report in publications. Thus, scientists are obligated to disclose any potential conflicts of interests they may have. The existence of potential conflicts of interest does not necessarily lead to bias, but transparency about them allows others to evaluate the possibility of improper influence.

Here’s an important example. Clair Patterson, a geochemist at Cal Tech in California, led the campaign to remove lead from gasoline in the 1960s and 1970s. Leaded gasoline contained lead tetraethyl, which is extremely toxic to human and non-human animals alike. Because the campaign against leaded gasoline threatened their profits, the fossil fuel industry—particularly the Ethyl Corporation—fought bitterly against Patterson’s research. Among their tactics was to pay another scientist, Robert Kehoe, to attest to the safety of leaded gasoline. Eventually, his dishonesty was revealed, and honest science carried the day. Lead was removed from gasoline, but only after generations of people in many countries around the world suffered from elevated lead levels in their blood, which leads to brain damage, chronic illness, birth defects, and increased death rates. Urban areas around the world still have elevated levels of lead in their soil from this period.

Another important form of protection against flaws in reasoning involves social norms and incentives governing the scientific community as a whole. One such norm is trust. Scientists’ trust in one another is the glue of scientific communities. For example, collaborative projects on climate change involve scientists with a range of different expertise, including climatologists, ecologists, physicists, statisticians, and economists. None of these scientists alone possesses comprehensive expertise to collect, analyze, and interpret the full range of evidence that bears on our understanding of anthropogenic climate change. These scientists must rely on each other and must trust one another’s scientific work.

Scientists also are expected to critically evaluate one another’s work by deciding whether results warrant publication, evaluating the strengths and weaknesses of research findings, and choosing whether and how to respond to published findings. One important form of critical evaluation is attempting to replicate others’ research. In replication, an experiment or study is performed again (often by different scientists) to determine whether the same findings obtain. If successful, the replicated results further confirm the ideas under investigation. If the results are not replicated, this raises doubts about the original work, such as the possibility that something unexpected was instead responsible for the finding. This is one way to think about what happened with continued evaluation of Clever Hans’s apparent math skills.

##### EXERCISES

1.13 Recall: Describe three types of influence of confirmation bias, and define observer-expectancy effect.

1.14 Recall: Describe how social structure is important to science, listing at least three ways in which it’s important that are discussed in this section.

1.15 Think: What does it mean to say scientific knowledge is produced by scientific communities instead of individuals? In light of your answer, explain why scientific communities need to be diverse across a range of characteristics.

1.16 Recall: Describe how social norms for individual scientists and for the scientific community are both important to the trustworthiness of science.

1.17 Recall: Describe three kinds of scientific fraud or scientific misconduct, giving an example of each.

1.18 Think:  How should trust and criticism be balanced in scientific communities, and why is this important to science? How should trust and skepticism of the public toward scientific findings be balanced, and why is this important for the public’s relationship to science?

### 1.4 DEFINING SCIENCE

After reading this section, you should be able to:

- Describe why it is difficult to define science and distinguish it from other pursuits
- Define pseudoscience and give examples
- Analyze whether a claim or topic of research counts as scientific using the checklist for science

#### Pseudoscience and the tricky work of defining science

Science is unrivaled in its ability to generate knowledge about our world. It has earned authority and legitimacy from centuries of successes and improvements that go beyond the expertise of any individual scientist or investigation. Many people and organizations are eager to lay claim to scientific legitimacy, and it’s sometimes difficult to discern whether they are entitled to it.

This is not a new problem. Karl Popper, the 20th-century philosopher encountered in the previous section, argued that some investigations thought to be scientific were instead pseudoscience, which means false, fake, or bogus science. Such nonscientific activities are designed to look enough like science to deceive people into thinking they have scientific legitimacy. A standard example of pseudoscience is astrology (not to be confused with astronomy, which is the scientific field that studies celestial objects in space). Astrology is commonly associated with horoscopes, which use zodiac signs to

make predictions about future events, relationships, destiny, and the like. Tests of astrological ideas have generated lots of empirical evidence against them, and advocates of astrology rarely engage in systematic attempts to empirically test their claims—claims that haven’t changed much since astrology peaked in popularity centuries ago. And yet,

even though astrology is bunk, it is still promoted as a legitimate source of knowledge. Massive numbers of astrologers, clairvoyants, psychics, and other charlatans take in billions of dollars every year for their consultations.

If astrology is pursued purely for entertainment, without pretense of generating knowledge or misleading anyone into thinking it’s doing so, then perhaps there’s no grounds for complaint. The central problem with pseudoscience is the deceptive attempt to appear scientific and, thus, to have the ability to generate scientific knowledge when it doesn’t.

In many cases, the specific intent of the advocates of pseudoscientific theories is to appeal to science’s self-correcting nature to call into doubt scientific findings supported by enough evidence to be considered established scientific knowledge. Anti-vaccination advocacy is like this. One popular anti-vaccination argument is that childhood vaccines increase the risk of autism. Extensive testing has demonstrated clearly and conclusively that there is no causal connection between vaccination regimes and the incidence of disorders like autism. This conclusion is scientific: it is based on evidence, is open to falsification, and would be rejected if sufficient evidence against it were found. But existing research is so extensive and compelling that the possibility of newfound disconfirming evidence is virtually nonexistent. Nonetheless, propaganda outlets and anti-vaccination groups peddle misinformation, trying to induce doubt by misconstruing the relevant research and with stories of children who were diagnosed with autism after vaccination. (This does regularly happen, for the simple reason that vaccination regimes and many symptoms of autism both tend to emerge in the same stage of early childhood.)

Another example of pseudoscience is creationism and intelligent design, which are attempts to explain the characteristics of living organisms by appeal to supernatural events, inspired by religious teachings. For close to a century now, “creation science” and later intelligent design were effectively advocated in the United States as alternative scientific theories to evolutionary theory, including publication of glossy textbooks and even a creationism-based alternative natural history museum. The basic thought behind both creationism and intelligent design is that living organisms are so complex that they couldn’t possibly have come about by evolution. This idea is not supported by evidence; it is actually debunked by the evidence, which, at the same time, clearly indicates the workings and effects of biological evolution. Notice that this does not imply that evolutionary theory has proven that there is no supernatural involvement; that would be beyond the purview of science. Rather, it’s just that the natural explanation of evolution successfully accounts for the natural phenomenon of complex lifeforms.

Healthcare is a common target for pseudoscience. Besides anti-vaccination advocacy, another example is conversion therapy, which is intervention intended to change a person’s sexual orientation. Conversion therapy pretends to be like psychological therapy and is still practiced in some circles, but it has been thoroughly shown to be ineffective and psychologically harmful. Other instances of pseudoscience might be less clear‐cut. Naturopathy is an approach to healthcare that emphasizes thinking about conditions of the whole body and looking to natural, folk, or indigenous remedies for health concerns. This approach might have some value when medical research is focused on precisely targeted medical intervention and when pharmaceutical drugs (but not herbal supplements) are subject to rigorous testing and regulation. Further, naturopathy training programs and licensure exist in some places. Nonetheless, some approaches endorsed in naturopathic medicine have been disproven with evidence. It can be difficult to judge whether naturopathy should be dismissed entirely as pseudoscience or might be rendered more legitimately science‐based with continued development or integration into mainstream medical practices.

Here’s another example of pseudoscience that comes from inside science. Naomi Oreskes and Erik Conway’s book, *Merchants of Doubt*, which also inspired a film of the same name, details how one group of well‐respected scientists in the United States provided legal testimony and spurred research that misled the public and enabled corporations to dodge responsibility for the health and environmental catastrophes of cigarettes, acid rain, climate change, and the toxin DDT. Apparently inspired by their political views, these scientists misused the authority of science to delay acceptance of established scientific knowledge that was inconvenient for powerful corporations.

As these examples reveal, discerning science from pseudoscience can be essential for health and safety, but doing so can be very difficult. Where is the line between harmless entertainment and pernicious fake knowledge, or between a new, underexplored alternative idea and a cynical attempt to inspire doubt in well‐established scientific knowledge? It seems we cannot just rely on whatever individual scientists tell us to believe. And some features of the nature of science described in the previous section might be shared by varieties of pseudoscience.

#### A checklist for science

We have discussed many distinctive features of the nature of science. These include aiming to generate knowledge, naturalism, empirical investigation, evidentialism, falsifiability and openness to falsification, and characteristic institutional structures. Some people have advocated one or another of these as the best way to define science, as with Popper’s falsificationism. Others have suggested these different features are together the hallmark features of science. We think that is the most promising approach. So, we define science as the inclusive social project of developing natural explanations for natural phenomena. These explanations are tested against empirical evidence and must be subject to open critique, refinement, and rejection.

The characterization of science developed here can provide a kind of checklist for assessing to what extent some activity qualifies as scientific, as pictured in Table 1.1. Consider how this characterization of science relates to our earlier example of climate change. First, science aims to generate knowledge. Climate science aims to generate knowledge of the extent and ways in which human activities are transforming Earth’s climate and of the impacts this transformation will have on weather systems, ecosystems, and human societies. Because science is naturalistic, it is limited to natural explanations of natural phenomena. The warming of the Earth’s climate is a natural phenomenon, subject to empirical investigation. The proposed natural explanation for this phenomenon is that human activities have generated unprecedented levels of greenhouse gases and the warming effect of those gases.

##### Table 1.1 Checklist of hallmark features of science 

✓ Aims to generate knowledge (knowledge-oriented)

✓ Provides natural explanations of natural phenomena (naturalism)

✓ Advances claims that can be tested against observational evidence (empiricism)

✓ Updates claims based on available evidence (evidentialism)

✓ Abandons any idea that has been thoroughly refuted (openness to falsification)

✓ Involves the broader scientific community (social and institutional structure)

All scientific claims must be testable, or falsifiable, with the use of empirical evidence, and claims must be supported by significant evidence to be accepted (or disconfirmed by sufficient evidence to be discarded). The claims that the concentration of atmospheric greenhouse gases has dramatically increased since the Industrial Revolution and that the last four decades are the warmest on record (for example) are both testable. We can describe the kinds of evidence that would lead us to reject these claims, but scientists have not found that evidence despite extensive investigation. These claims have not been falsified; they are accepted by the scientific community only because there is strong evidence in their favor.

As new evidence becomes available, scientific claims are corroborated, revised, corrected, or rejected through the collaborative work of researchers embedded in the social and institutional structures of science. Climate change research involves numerous scientists utilizing techniques from different fields of science, and our understanding of climate change and predictions of its effects are constantly fine-tuned. The basic idea of anthropogenic climate change has persisted through all of this—indeed has become more broadly held—because no challenges to the idea or to the research supporting it have been successful. Multiple studies published in peer-reviewed scientific journals independently confirm that glacier retreat and climate-warming trends over the past century are due to human activities, and most of the leading scientific organizations worldwide endorse this conclusion.

Here’s an obvious contrast with science: jazz. Jazz artists do not collect measurements or other similar forms of evidence to test hypotheses about the value of a piece of work, and disagreements about the value of, say, Ella Fitzgerald’s Over the Rainbow cannot be settled by running experiments, conducting empirical studies, or developing models. Unlike scientists, jazz musicians do not aim to find natural explanations of features of the natural world with their practices.

Now consider astrology, a canonical example of pseudoscience introduced previously. The primary claims made in astrology, such as horoscope predictions, are not designed to be falsifiable; in fact, many are specifically designed to be unfalsifiable. They are vague in ways that allow many different interpretations, and so, for any interpretation that is wrong, another can be offered in its place. Further, the systems of horoscopes used by astrologists are inconsistent with well-understood basic theories of biology, physics, and psychology. This violates the expectation of the collaborative exchange of ideas among scientists. Astrology is not science.

Astrology may be a harmless fad, with negative consequences largely confined to misspent leisure time and money. Other pseudoscientific projects are much more dangerous. Denials of anthropogenic climate change—despite overwhelming evidence—have contributed to a lack of political will to address the climate crisis, a failure that is beginning to lead to catastrophic consequences. The campaign of denialism described in Merchants of Doubt involved well-established scientists introducing doubt and distraction about topics beyond their scientific expertise to influence political outcomes. Their denial of climate change was not designed to be falsifiable: no amount of evidence would change their mind. Some climate change deniers have even rejected the idea that science is a trustworthy source of knowledge in order to hold fast to their rejection of climate change.

##### Box 1.3 Evaluating scientific expertise

Imagine you are asked to vote on a policy about banning cannabis. The potential ban appeals to research showing that cannabis causes schizophrenia. Suppose you do not know much about cannabinoids and their psychiatric effects. Where would you search for relevant, trustworthy information? Without expertise in the relevant science, it can be difficult to evaluate scientific research. You might find on social media two alleged experts who disagree about the causal claim. How should you decide who is the most credible?

The most straightforward way to evaluate scientific claims is to assess the quality of the arguments presented by the experts. But this can be difficult, as scientific information can be technical and hard to understand for non-experts. For this reason, it is also important to consider the credentials and reputation of the alleged experts, including the relevance of their qualifications and their accomplishments in their field, and look out for any possible sources of conflict of interest or bias. And, because science is a collaborative enterprise, try to learn what the consensus or near-consensus is in the relevant area of research. This is more important than what any individual scientist thinks. So, you should also beware the maverick scientist who claims to have refuted the consensus in the field!

#### Science’s limitations

While science is our best route to knowledge about the world around us and to developing innovations based on that knowledge, it is also important to recognize what it doesn’t do.

Scientists try to gain knowledge, that is, to develop natural explanations of natural phenomena. The list of the phenomena investigated in science is long; in principle, it includes everything in our universe. But there are some important limitations to the scope of science. Science doesn’t replace or limit nonscientific intellectual pursuits, like literature, music, and painting—or politics for that matter. Basing our scientific knowledge about climate change on fluctuating political agendas would be a mistake. But, when it comes to addressing climate change with policy interventions, debating which steps are politically feasible and desirable is fair game for politicians. Of course, knowledge from climate science and other scientific fields such as economics, sociology, and psychology should be considered in these deliberations.

Scientific knowledge differs from theological doctrine and religious practice, too. Unlike religious practitioners, scientists attempt to explain things without appeal to supernatural entities or influences, such as deities or miracles, or to literary allegories or culturally significant myths. Furthermore, faith has a central place in many religions, while it should have none in science. Of course, one can be religious in myriad ways, and many people—scientists included—are both religious and believers in scientific knowledge. People disagree about the role religion should play in our society, but whatever role that might be, science is not designed to occupy it.

Scientism is a derogatory term for an excessive belief in science as a solution to every possible problem—including philosophical problems about the meaning of life and our place in the universe. Like pseudoscience, scientism expresses a kind of intellectual arrogance, where one gives excessive deference to science as the sole source of knowledge we might acquire and the only way to find correct answers to any question of human concern we might ask. In public debates, symptoms of scientism include generic slogans like “because science says so” and “science doesn’t care what you believe,” which are ironically designed to halt discussion rather than to promote it. Also included are quick dismissals of other humanistic endeavors and disciplines like history and philosophy as being “anti-science.” We think it is important to distinguish the thought that science is a uniquely trustworthy source of a certain kind of knowledge from ideas that might sound similar, such as that professional science is the only way to have knowledge of any kind or should be the basis of one’s entire worldview.

##### EXERCISES

1.19 Recall: Define the term pseudoscience and give two examples of pseudoscience discussed in the section. For each, describe why it counts as pseudoscience.

1.20 Apply: Choose one example of pseudoscience discussed in this section and evaluate it using the checklist of science. Describe how it is similar to science and how it is different. Can you identify features of the example you’ve chosen that seem to be intended to appear more like science than they are?

1.21 Think: What’s distinctive about science, in comparison to activities like literature, music, and art, as a source of knowledge about the world? Do you think there are any important differences between scientific and artistic ways of gaining knowledge? Support your answers with justification.

1.22 Think: Why must science be limited to the study of natural phenomena? Why must it give only natural explanations? Can you think of any scientific projects that don’t seem to satisfy these requirements? If so, describe one such project, making clear why you think it might not be naturalistic. If not, describe a nonscientific project that seems to be non-naturalistic and say why.

1.23 Apply: Search the internet (news websites, magazines, blogs, etc.) for a story about a finding purporting to be based on science, and answer the following questions about it. Include a link to your source when submitting your response. (Alternatively, your instructor may provide you with a story to analyze.)

Answer the following questions about the story:

1. a. What is the source? Is the person making the claims someone with genuine expertise in what they’re claiming?
2. b. Does it seem like there’s any conflict of interest? Why or why not?
3. c. Does the claim involve vague or ambiguous language?
4. d. Do the claims fit with other well-confirmed scientific theories?
5. e. What is the evidence cited in support of the claim?
6. f. Does this describe good science? Why or why not?

1.24 Recall: Define scientism and describe why it is a problem. Give an example of legitimate reasoning leading to knowledge that occurs outside of professional science.

##### FURTHER READING

For more on political influence used to cast doubt on climate change research and other scientific findings, see Oreskes, N., & Conway, E. (2010). Merchants of doubt. Bloomsbury.

For an accessible online resource about the nature of science and scientific processes, see the website Understanding science. https://undsci.berkeley.edu

For more on how social norms and social structures influence scientific inquiry, see Merton, R. K. (1942). Science and technology in a democratic order. Journal of Legal and Political Sociology, 1, 115–126. Reprinted with the title “The normative structure of science” in Merton, R. K. (1973). The sociology of science: Theoretical and empirical investigations. University of Chicago Press.

Wilson, C., & Weisberg, M. (Eds.). (2018). *Scientific collaboration and collective knowledge*. Oxford University Press.

For more on the demarcation between science and pseudoscience, see Pigliucci, M., & Boudry, M. (Eds.). (2013). *Philosophy of pseudoscience: Reconsidering the demarcation problem*. University of Chicago Press.
