## CHAPTER 13 Science in society

### 13.1 ANIMAL BEHAVIOR AND SCIENCE’S SOCIAL CONTEXT

After reading this section, you should be able to:

- Summarize sexual selection theory and give examples of a showy trait and an aggressive trait thought to evolve through sexual selection
- List three concerns with classic sexual selection theory and suggestions for how the theory might be expanded or rethought on the basis of these concerns
- Describe three ways in which science can be influenced by its social and historical context

#### Sex and reproductive strategies in animals

Some animal traits have clear value to the animal. Predators like the leopard have eyes on the front of their head to make it easier to track their prey, while prey like the antelope have eyes on the sides of their head so they can keep an eye out to ensure their safety. Eye placement evolved differently in predator lineages and prey lineages because each placement has different advantages.

Other traits are less obvious in their function. Since Charles Darwin first developed the scientific theory of evolution by natural selection in the 19th century, scientists have puzzled over the emergence and biological function of traits like the peacock’s long, colorful tail feathers, also called a train. What’s puzzling about the peacock’s showy train is that it makes it easier for predators to spot the peacock and more difficult for the peacock to move quickly. And it’s not the kind of trait that would just occur by accident!

The widely accepted explanation for the peacock’s colorful train is that the showy tail feathers don’t help with survival but, instead, with reproduction. This trait—and many others, across many species of animals—is thought to evolve through sexual selection, when a trait is valuable simply because it appeals to potential mating partners. If the trait is inherited by offspring, then sexual selection can explain how the trait can become more pronounced and widespread over time. So, the peacock, over time, is thought to have evolved a longer, showier train because of this process of sexual selection.

Sexual selection theory traditionally emphasizes how female mate choice can lead males to evolve showy traits—the peacock’s train, the cardinal’s red coloration, the lion’s mane—and how male competition for mating opportunities with females can lead males to evolve aggressive traits—the elephant seal’s huge size and aggressive behavior, the deer’s large antlers, the rhinoceros beetle’s horns. But some scientists have criticized this focus. Among them are anthropologist and primatologist Sarah Blaffer Hrdy and biologist Joan Roughgarden.

Hrdy researched primate behavior in the second half of the 20th century. She criticized the assumption behind sexual selection theory that the norm across animal species is for choosy females to select among many promiscuous males who are eager for mating opportunities. Darwin presented this as a matter of the “coy” female engaging with the “eager” male. The problem with this idea is that, across many species, females are actually quite eager to engage sexually. So, a basic assumption of sexual selection theory turns out often to be inaccurate. Beyond that, Hrdy emphasized that sexual behavior is a very small portion of all animals’ lives—also relevant is time spent finding food, resting, fleeing dangers, rearing their young, playing, building homes, socializing, and so on.

Joan Roughgarden is a biologist who researched genetics and, later in her career in the early 21st century, turned to research on the variety of sexual, reproductive, and parental strategies across animal species. Roughgarden’s book *Evolution’s Rainbow* catalogs that variety. Animals engage in a wide variety of mating strategies, such as bluegill sunfish, which have three distinct male types with dramatically different body sizes, appearances, and mating strategies. Roughgarden suggests these different types should be thought of as distinct genders. She also emphasized the wide variety of factors that determine the sex of animals, that is, whether they are male or female. In some species, including humans, genes play a central role in determining whether an animal is female or male. In others, like frogs, environmental factors such as temperature determine sex, and in still other species, sex of an individual changes over their lifespan.

Animals also vary widely in their parental strategies. Some species leave their offspring to fend for themselves immediately, while other species invest significantly in caring for and protecting their young. Sexual selection theory has emphasized female contribution to caring for offspring. But, in species that care for their young, this is sometimes a two-parent project; sometimes a male project, as with seahorses, whose males carry the young around in a pouch much like kangaroos; and sometimes a group collaboration, where larger social groups collectively rear their young, as in several species of birds.

After cataloging the extensive variation in animals’ sexual, reproductive, and parental strategies, Roughgarden began to reconsider how those strategies may have evolved. She criticized sexual selection theory for focusing exclusively on reproductive sexual encounters, ignoring how sexual activities can play nonreproductive social roles like resolving conflicts, and how pairs and communities can cooperate to successfully raise offspring. She also pointed out that animals engage in a wide variety of social encounters, with members of the opposite sex and same sex alike, and that these can also have evolutionary significance.

Roughgarden has developed several competing hypotheses for traits targeted by sexual selection theory. These hypotheses emphasize extensive social exchanges and cooperation as potential reasons for the evolution of traits typically explained as the result of sexual selection. While most biologists still think of sexual selection theory as a cornerstone of evolutionary theory, many biologists’ understanding of sexual selection theory has at least been updated to acknowledge more variation in how reproductive pressure influences evolution. Sometimes females compete for reproductive access to males, and this has led, in some cases, to females having showy traits or aggressive traits. Sometimes males invest more in offspring care than females do. And sometimes broader social groups are relevant to the evolution of sexual and reproductive behaviors.

If Roughgarden and Hrdy are right, then more attention should be paid to the evolutionary impacts of how animals engage with one another—sexually, cooperatively, and competitively—outside of reproduction. This might lead some traits that have been explained as instances of sexual selection to be reclassified as the evolutionary result of the influence of social dynamics.

Returning to the example of the peacock’s colorful tail feathers, this is still broadly accepted as a primary example of a showy trait resulting from sexual selection. But more than a decade ago, researchers in Japan published a paper showing that, in local feral populations of peafowl, more elaborate tail feathers weren’t associated with mating success. Male displays involving the colorful train are certainly involved in mating behavior. But other researchers have found that displaying the tail feathers by fanning them out in mating rituals serves to amplify peacocks’ verbal calls, which raises the question of whether the trains themselves are important to mating or just their role in amplifying verbal cues. Furthermore, peacocks also display their tail feathers when faced with a predator, making themselves seem larger and distracting the predator, as a bite to the colorful train simply leads to the loss of some feathers rather than bodily injury. Sexual selection theory is meant to account for traits that wouldn’t evolve by natural selection alone, but it seems like the peacock’s colorful tail feathers may have direct contributions to survival as well.

#### Science in a social context

Beyond her primatology research, Sarah Blaffer Hrdy also asked why primatologists began to take issue with standard sexual selection theory in the 1970s, first beginning to notice the active sexual lives of female primates. She suggests that, especially when studying primates, scientists tend to identify with and observe more closely animals of the same sex as themselves. Humans are, after all, one species of primate. So, in Hrdy’s view, an increasing number of women in the field of primatology brought with it increasing attention to female primates and their behaviors, instead of the previous focus on male primates with females more in the background.

Joan Roughgarden is also reflective about how her social identity influenced her research. In the preface to her book about variability in sex and reproduction in animals, she reflects on attending her first Pride Parade in San Francisco and transitioning shortly after to confirm her identity as a transgender woman. These experiences led her to wonder about all the diversity across the animal kingdom, and how evolution and development lead to such diversity. Roughgarden associates this with her growing realization that sexual selection theory was overly limited, as well as with the insight that “kindness and cooperation are basic to biological nature.”

Way back in Chapter 2, we introduced the idea that science—including both its aims and its methods—is influenced by social values, or priorities and moral principles accepted in some community. In the scientific investigation of sex and reproduction in the animal kingdom, the influence is felt in the question of which sex is focused on (male or female), on whether reproductive variability beyond biological sexes—what Roughgarden urges us to think of as different genders—is investigated, on which traits and patterns are emphasized, and perhaps even on whether the focus is on the cooperative or competitive value of traits.

Because scientific reasoning is a fundamentally human endeavor, it always occurs in specific social, institutional, and historical contexts. Scientists make observations, develop theories, make discoveries, and interact with one another all within specific interpersonal, institutional, and cultural circumstances. Further, science is embedded in institutional structures like universities, labs, museums, journals, and publishing companies. These social contexts and institutions in which science occurs are influenced by history, by who is part of them, and by the social identities scientists bring to their work.

Further, social and historical context influences the nature of science. Even as science aspires to produce knowledge that is not limited by specific perspective, scientific theories are in some ways creatures of the times, places, and people who created them. Some have suggested that Darwin’s statement of sexual selection theory was strongly influenced by Victorian moral sentiment in its assumption that, throughout the animal kingdom, male animals are promiscuous and aggressive and female animals “coy” and selective. This looks suspiciously like gender norms in Victorian England, Darwin’s cultural setting. While Darwinian evolutionary theory was certainly a tremendous step forward for biology, it was also influenced by the time and place of its creation, and perhaps by the interests and personal values of the individuals who created it.

So, science seems to be shaped by its social, institutional, and historical context. Science also is regularly used to promote particular social aims, either explicitly or implicitly. Specific scientific aims can support different social aims. Consider how Roughgarden is explicit about her motivation to explore variation in sex and reproductive strategies in the animal kingdom in order to support social aims of inclusion. Even if some scientific research does not relate directly to social aims, a scientist’s interests and values may still influence how the aims of their scientific research connect with social concerns.

The difficult truth is that, throughout history, science has often been used to promote objectionable social aims and, at times, has even been pursued in ways that incorporate morally horrendous views like eugenics and scientific racism. Science has been used to expand power over others, to invent nuclear and chemical weapons for the purpose of mass destruction, and to amass wealth for the few, as with research for the fossil fuel industry. Science has also been used to promote misinformation, as when the British doctor Andrew Wakefield fraudulently claimed that the combined measles, mumps, and rubella (MMR) vaccine was linked to autism or when tobacco corporations paid scientists to present cancer research in a way calculated to mislead the public.

Science has also been used to directly harm and oppress marginalized groups, as when the Nazis ran deeply cruel experiments on the prisoners of concentration camps and when the US Public Health Service ran the Tuskegee syphilis experiment. In this clinical study, researchers withheld treatment from 399 impoverished, rural, Black men who had syphilis. They never informed the participants that they had syphilis or that there was a cure for the disease. Scientific research has also indirectly supported racism and sexism by focusing on aims like identifying a genetic basis for racial differences in intelligence or neurological differences between men’s and women’s brains.

All of this suggests that an important aspect of investigating science is learning about science’s relationship to society. We need to understand how science is shaped by scientific and historical context, ways in which science can be influenced by social values, how to uncover problematic values or problematic roles for values in science, and how science can be used to promote positive social aims.

#####  EXERCISES

13.1 Recall: Summarize sexual selection theory and give one example of a showy trait and one example of an aggressive trait thought to evolve through sexual selection.

13.2 Apply: Choose an example of a showy or aggressive trait, either from the text or a new one. Using Google Scholar, a library catalogue, or a similar search tool, find 3–5 research articles focused on that trait as an instance of sexual selection. Summarize the main finding of each article in one sentence; you can probably do this just by reading their titles and abstracts. Do these articles together provide adequate support for the hypothesis that the trait is an instance of sexual selection? Why or why not?

13.3 Recall: Describe (a) Hrdy’s criticism of the assumption that female animals are “coy” while males are “eager,” (b) Roughgarden’s point about variety of sexual, reproductive, and parental strategies, and (c) Roughgarden’s idea about how cooperation might be important instead of competition. For each, say how it challenges sexual selection theory.

13.4 Recall: How did Hrdy think research into sexual selection was influenced by social factors? How did Roughgarden think research into sexual selection was influenced by social factors?

13.5 Think: In your own words, describe how you think historical and social factors have influenced research into the evolution of sex, reproduction, and parental strategies. Give one example of an influence that you think was problematic for scientific or ethical reasons and one example of an influence that you think was acceptable (scientifically and ethically).

13.6 Apply: Choose an example of a scientific theory or finding discussed anywhere in this book. Describe how you think historical and social factors may have influenced the research bearing on that theory or finding. Does the influence by historical and social factors you identified call the theory or finding into question, or not?

### 13.2 PARTICIPATION IN SCIENCE

After reading this section, you should be able to:

- Describe how people with some social identities have been historically excluded from or marginalized in science
- List three ways in which diversity of scientists is beneficial to science
- Indicate how members of the public can be included in scientific research and how this can affect scientific research

---

#### Exclusion from science

Just as we must acknowledge the historic contribution of science to immoral social aims and objectionable values, including classism, racism, and sexism, we also must acknowledge that science has never been—and still is not—fully inclusive. This means that many people—because of their geographical location, institutional affiliation, language, sex, race, or creed—do not receive a fair chance to participate in and contribute to scientific inquiry. Historically, the institutions that house today’s science disproportionately developed in Europe and, later, the United States and predominantly included wealthy, White men. Women, people of color, people without wealth, and people in other nations have always contributed to science. But people from these and other marginalized social groups have historically had very limited access to resources to make scientific contributions and very little recognition afforded to them for their scientific contributions.

Polymath Alan Turing did groundbreaking research in computer science, logic, mathematics, cryptography, and morphology in Great Britain. During World War II, he helped crack the code used by the Nazis to protect their military communication, an achievement that many historians believe was the single greatest contribution to the Allied victory. Turing was also a visionary of artificial intelligence. You may have heard of the Turing machine and Turing test that he invented; he anticipated that human intelligence would one day be matched by machines. Turing was also gay, and at the time this was illegal in Britain. Despite his groundbreaking contributions to the computer, or “digital,” revolution, Turing was arrested and chemically castrated by the British government. Humiliated and resentful, he committed suicide at the age of 41.

If being outed as gay in mid-20th century Great Britain was awful, matters were no brighter for women in science for most of history. Cecilia Payne-Gaposchkin’s groundbreaking dissertation Stellar Atmospheres in 1925 became a cornerstone of modern astrophysics, but she couldn’t get a professorship, so she had to do low-paying adjunct teaching for the next 20 years. Rosalind Franklin was a chemist and x-ray crystallographer, who we mentioned in Chapter 5 for her important contributions to the discovery of DNA’s structure in the mid-20th century. Franklin was responsible for an x-ray diffraction image that was shared with Watson and Crick without her knowledge (pictured in Figure 13.2). After seeing that image, Watson and Crick developed their physical model of DNA. They went down in history as having discovered DNA’s double helix structure, eventually winning the Nobel Prize for this work. In contrast, Franklin’s enormous contributions to the discovery were recognized only after her death.

A similar story is that of neuroscientist Kathleen Montagu, who published her discovery of the neurochemical dopamine in the human brain in 1957. Her work was largely overshadowed by a very similar discovery three months later by Swedish neuropharmacologist and Nobel Prize winner Arvid Carlsson and colleagues. This is a common enough phenomenon that is has been named. The Matilda effect is the bias against recognizing women scientists’ achievements, whose work is often uncredited or else attributed to their male colleagues instead.

Societal prejudice and structural exclusion have made it more difficult for not only women but also racial and ethnic minorities, sexual and gender minorities, people with disabilities, first-generation college students, people from low socioeconomic backgrounds, residents of the Global South (Latin America, Asia, Africa, and Oceania), and other marginalized groups to be supported in their scientific work and even to become scientists in the first place. Even today, opportunities and rewards in science disproportionately go to men from families with financial resources and college educations and who live in wealthy nations. That said, the inclusion of people from social groups underrepresented in science is increasing, as more attention is focused on making science more inclusive and equitable.

#### Diversity in science

When only certain kinds of people participate in science, science suffers. Systemic exclusion and marginalization result in science squandering or losing out entirely on the contributions of the people who were excluded or marginalized. A second way in which science suffers is that there are fewer role models for aspiring scientists. When scientists like Turing or Franklin are dishonored or not acknowledged, younger people do not have the opportunity to look up to them. When groups of people are systematically underrepresented and marginalized in science, young people may not see themselves as potential participants in science.

These are reasons for the scientific establishment to prioritize inclusion, that is, to take steps to ensure people with a full range of backgrounds have a fair opportunity to become scientists and to gain recognition for their achievements. We should also look back to the history of science, revisiting standard accounts of who discovered what, who qualified as scientists, and which societies influenced the development of science as an institution. We have tried to keep that in mind as we selected examples and scientists to feature in this book, though we acknowledge we did not fully succeed. There is a broad project needed, and to some extent underway, to update our collective understanding of science to more fully credit the full range of individuals and societies that shaped it.

Diversity in science has important effects beyond simply not losing out on scientific discoveries or future scientists. Who participates in science and who is excluded affects the nature of scientific knowledge and its trustworthiness. The features of scientists—nationality, gender and sexuality, socioeconomic background, race and ethnicity, religious belief, political affiliation—all help determine what questions scientists are interested to investigate, what bold conjectures they come up with, and perhaps in some cases which methods they tend to use. When a group of scientists in some field is sufficiently diverse, all differences among them can contribute to the range of questions, richness of ideas, and ultimately the quality of inquiry. If, instead, only certain kinds of people participate in science or in some particular field of science, then the kinds of questions posed, ideas generated, and interpretations of data may reflect the limited perspectives of those scientists. For example, recall Hrdy’s observation of the changes to primatology research that occurred when a critical mass of women became primatologists. And, back to our point about role models, the influx of women to primatology might well have been influenced by the publicity received by Jane Goodall’s research on chimpanzees in the mid-20th century.

Charles Henry Turner was an African American zoologist who pioneered the study of animal cognition, particularly in insects. Born in the US just two years after the end of slavery, Turner was the first Black student to graduate with a master’s degree from the University of Cincinnati and the first Black student to be awarded a PhD at the University of Chicago. Turner was a victim of racism and could not find work in a university. He worked in an all-Black high school, while continuing his research on animal behavior. Turner rejected the prevailing ideas of the time that animals like birds, bees, and ants do not have sophisticated abilities of perception or cognition. His research demonstrated that these animals possess impressive powers of memory, learning, and problem-solving, drawing attention to sophisticated behaviors like mound building in ants and hunting habits of wasps. Although Turner could not work in a university and did not have access to adequate laboratory equipment, he still managed to publish the results of his studies in prestigious scientific journals. His research was ahead of its time, predating more recent cognitivist approaches to analyzing and explaining animal behavior.

The value of diversity of science, then, is more than just who is recognized for what discovery, how breakthroughs are received, and who gets to be a scientist. People with different social identities can bring different styles of reasoning to the table, and scientific progress often demands creativity and seeing things anew. For these reasons, the conscious inclusion and encouragement of people from diverse social groups and with diverse social identities to participate in science doesn’t just benefit those individuals and benefit society; it also makes science more successful at achieving its paramount goal of generating knowledge.

#### Public participation in science

Science welcoming new scientists from diverse social groups and with diverse social identities is one way to gain new perspectives in science. Another way, which is also gaining popularity, is to include members of the public as collaborators in scientific research. Participatory research is any scientific research in which members of the public who aren’t trained scientists participate in doing the research. Participatory research goes by many names; you may have heard it called citizen science, community-based research, or action research. We encountered this in Chapter 7’s discussion of how scientific research helped uncover the Flint water crisis. Community members in Flint reached out to environmental scientists for help, and a local pediatrician led research into pediatric lead exposure.

##### Box 13.1 Open science

The term open science indicates several practices that support the free sharing of scientific research and calls for broadening the demographic composition and theoretical approaches of scientific research. The overarching aim of open science is to enhance the quality of research, accelerate the rate of discovery, and make science more inclusive.

Open science has several dimensions. One is open access to research products, where scholarly outputs such as software, scientific articles, and books are disseminated open source—free to read, use, and share by anybody. An example is open-access repositories of electronic preprints of scientific papers such as arXiv. Another more controversial example is Sci-Hub, a shadow library website created by Kazakhstani computer programmer Alexandra Elbakyan, providing free access to millions of published research papers without regard to copyright and paywalls.

Another dimension of open science is pedagogical. The aim here is to make a diverse range of teaching and learning materials freely available and accessible through schools, libraries, museums, and even theaters. A third dimension of open science is preregistration and open data: specifying one’s research plans in advance of a study and making all data available and accessible in public repositories. These all aim to improve the transparency, accountability, and replicability of research. Finally, another dimension are calls to identify the social, economic, and political dynamics that have historically shaped and still shape participation in science and to work to empower marginalized scientists, striving to make scientific institutions fairer.

Scientists sometimes choose to include the public in research efforts in order to increase the amount of data that can be collected. For example, the Cornell Lab of Ornithology in the United States has involved members of the public in collecting data about bird breeding, courtship, habitats, and colors for decades, which has enabled more data and in a broader range of locations. But that’s not the only benefit from public participation in the Cornell Lab’s research. Participation in gathering data about birds is also an opportunity for students and interested adults to learn more about birds and about how scientific research occurs. And it is an important opportunity for education about conservation and participation in conservation efforts.

Some participatory research even involves members of the public in shaping the research aims and methods. When research focuses on topics of community interest, such as health outcomes, local environmental conservation, and community access to services, involving members of the relevant communities early in the process of designing the research enables scientists to benefit from their inside perspective. This can help the research target issues of genuine community concern, in ways the community will value, and it can help legitimize the research in community members’ eyes, which can help with recruiting participants into the study as subjects (to respond to surveys, be interviewed, or donate genetic samples, for example). In Chapter 2, we mentioned how local, indigenous knowledge is increasingly recognized as valuable for certain kinds of scientific research, for example, on how to adapt to local effects of climate change. That is one pattern participatory research can follow.

Because of science’s history of exclusion and its contributions to injustice, members of some communities hesitate to participate in scientific research. If participatory research is pursued with true concern for community member’s priorities and is developed to empower public participants and their communities, then participatory research can perhaps help ameliorate this problem. But it’s worth pointing out that participatory research can also be pursued in problematic ways. This can occur, for instance, if researchers do not empower public participants to influence the research, do not heed community members’ recommendations, or do not follow through in their commitments to the community related to the research. Indeed, science has developed a bad reputation for so-called helicopter or parachute research, where scientists from wealthy nations visit poorer countries to study underserved communities and local ecosystems, perhaps collecting artifacts or biological samples, and publishing results in scientific journals with no involvement from local scientists and without concern for whether and how the community is impacted or whether community members have access to the knowledge generated.

##### EXERCISES

13.7 Recall: Describe how people with some social identities have been historically excluded from or marginalized in science. List three social identities affected by this exclusion and marginalization.

13.8 Apply: Choose one social identity underrepresented in science (such as a racial or ethnic minority, a sexual or gender minority, people with disabilities, first-generation college students, people from low socioeconomic backgrounds, or residents of the Global South). Use the internet to identify three prominent scientists with the social identity you have selected. For each, provide their name, the approximate time period of their career, their research field(s), and a brief summary of their main scientific contributions.

13.9 Recall: List three ways in which diversity of scientists is beneficial to science.

13.10 Think: Describe three steps that you think could be taken to increase diversity in science. Then, indicate any concerns or downsides you can think of for each of the steps. Which of the steps you described do you think should be implemented, and why?

13.11 Recall: Define participatory research. Describe three ways in which participatory research can improve scientific research.

13.12 Apply: Go to the website www.zooniverse.org; this is a major platform for participatory research projects. Look at some of the projects on the website and find one that’s particularly interesting to you. Describe the project, what the aim of the research is, and why you think it is designed to include public participation. What is the value for the scientific research of public participation? What is the value for the public of participating in this research? Make sure you provide the name and link of the project you chose.

### 13.3 SOCIAL VALUES AND SCIENCE

After reading this section, you should be able to:

- Define the value-free ideal and describe what about it is correct and what is incorrect
- Give an example of when values have influenced science in a problematic way
- List five ways in which values influence science in legitimate ways and give an example of each

#### The value-free ideal

In Chapter 1, we emphasized how the institution of science has been developed to control for and overcome human limitations in reasoning like confirmation bias. One feature of this is that science is supposed to provide a way to subject our pre-existing ideas to rigorous test. Wanting something to be true isn’t good grounds for believing it is true, and science provides methods of hypothesis-testing, reasoning, and theorizing to evaluate the grounds for our beliefs. This idea inspires what has been called the value-free ideal for science, which is the thesis that scientific reasoning should proceed free from the influence of our values—such as moral, social, or political beliefs.

There is something right about the value-free ideal. Whether or not we want something to be true is irrelevant to whether it is in fact true, and science aims at the production of genuine knowledge. So, in science, hypotheses and theories should be judged not for their desirability but instead for the grounds for thinking they are true. Some scientific questions—about the reality of climate change, humans’ evolutionary history, and gender differences in cognition, for example—may evoke emotional reactions, but those emotions aren’t relevant to how scientific research bears on the questions. Instead, these questions can only be answered by conducting experiments or studies, constructing models, evaluating evidence, applying statistical reasoning—by applying the recipes for science.

On the other hand, it is clear that science regularly is influenced by values. For example, we mentioned earlier how Darwin’s evolutionary theory encodes Victorian morality and how Hrdy’s and Roughgarden’s research was inspired by values each of these scientists held. Positing the value-free ideal as an ideal enables us to acknowledge that sometimes values have in fact played a role in science, while insisting that they should not. Still, if science regularly does incorporate values, it’s worth asking whether being value-free should even be considered an ideal for science to aspire to.

Indeed, we discussed in Chapter 2 how social values can influence both the aims and methods of science. Is discovering a vaccine for the Zika virus, which is easily transmitted to humans by mosquito bites and leads to serious birth defects when pregnant women are infected, more important than discovering new facts about quasars, pulsars, supernovas, or other astral phenomena? Deciding this requires consideration of social values. It’s clear that the US Public Health Service should not have withheld syphilis treatment from 399 impoverished Black men without their knowledge in the Tuskegee syphilis experiment; saying why requires consideration of values. The value-free ideal is not only inaccurate of how science has in fact played out; it’s also undesirable as an ideal for science to aspire to. Values should, at least in some ways, influence scientific reasoning.

#### How values shape science

The value-free ideal suggests that science should simply be a source of objective facts about the world, immune to influence by human values. On the other extreme, some people believe science only serves preexisting political or economic values. The right view of how values should influence science is somewhere between these two extremes. Science is not and should not be value-free, but there are ways in which science should limit the influence of values.

Scientists are human beings with different moral, political, and religious values, and we have seen that the social context for science and who participates in science can both influence scientific findings. And yet, the recipes for science are designed to limit the kinds of influence social and individual values have on science. When scientists’ values lead them to violate the recipes for science—acceptable approaches to data collection and modeling, to hypothesis-testing and abductive reasoning, to statistical analysis, and so forth—this is illegitimate. When scientists use values to supplement, inform, or guide the use of the recipes for science, this can be legitimate.

In his book, *A Tapestry of Values*, philosopher Kevin Elliott divides the legitimate roles values can play in science into five categories, as helping to answer five different questions. These questions are summarized in Table 13.1. Answers to these questions are needed in order to know which scientific methods to employ, on which phenomena, and to what end. These roles for values thus align with our suggestion that legitimate uses of values supplement or guide the methods of science but do not violate those methods.

To begin, scientists’ individual values and societies’ collectively held values help answer the first question about what to study. Individually, a researcher’s interests and values surely shapes what field of science they pursue, which lab they work in, and what problems they tackle. Collectively, we choose what kinds of scientific research to support when funding agencies, including tax-supported governmental agencies, designate the areas of research they fund and which specific research projects in those areas to fund.

Beyond what to study, values also inform decisions about how phenomena should be studied. Scientists can bring different questions, methods, and background assumptions to bear on any given topic, and these choices in how research is pursued reflect

##### Five questions that our values help answer when doing science

| Question                                 | Example                                                      |
| ---------------------------------------- | ------------------------------------------------------------ |
| 1. What should we study?                 | what kind of research is prioritized for funding             |
| 2. How should we study it?               | how the initial hypothesis and assumptions about the causal background both guide experimental design |
| 3. What are we trying to accomplish?     | getting the most accurate information vs. accurate-enough information quickly enough to guide policy |
| 4. What if we are uncertain?             | how much evidence to require before accepting or rejecting a given hypothesis |
| 5. How should we talk about the results? | the level of certainty conveyed to the public about some scientific finding |

Source: Adapted from Elliott (2017)

Researchers’ and society’s values. One instance of this influence is how the initial hypothesis and assumptions about the causal background both guide experimental design, including the nature of the intervention and which extraneous variables to control. As with the initial choice of what to study, funding agencies can also influence how phenomena are studied. For example, research into depression can focus on the efficacy of cognitive therapy; the role of sleep, diet, and exercise; or the efficacy of pharmaceutical intervention. The choice to strongly prioritize pharmaceutical intervention to the exclusion of other focuses reflects the outsized influence drug companies have had on medical science.

The third question that a focus on values helps to answer is what, exactly, scientists are trying to accomplish in studying some phenomenon. This is an even more fine-grained decision than just what to study and how to study it. In climate research, for example, scientists might prioritize getting information about climate trends available quickly so that it can guide policy, or they might prioritize getting as accurate of information as possible, no matter how long it takes. This decision about the aim of research is influenced by values, including views about the social role the scientific research is expected to have.

Fourth, values influence how scientists proceed in the face of uncertainty. Scientific results are never free from uncertainty. There’s the basic problem of measurement error. We’ve also seen that, if observations don’t match expectations, it could be the fault of the hypothesis, or it could be the fault of some auxiliary hypothesis. In an experiment, no matter how perfectly controlled, there’s always the chance that an unexpected confounding variable has interfered with the finding. In statistical hypothesis-testing, scientists choose whether to reject the null hypothesis or not, and either choice could be wrong, resulting in a type I error (false positive) or type II error (false negative). These are just a few examples of the unavoidable uncertainty in science and the need to choose how to proceed in the face of inductive risk, that is, the risk of wrongly accepting or rejecting a scientific hypothesis. These kinds of uncertainty are all forms of underdetermination. Recall from Chapter 3 that underdetermination is when the evidence available to scientists is insufficient to determine which of multiple theories or hypotheses is true. Some believe that there is even permanent underdetermination in science: that there will never be enough evidence to conclusively decide in favor of one hypothesis or theory and against all possible alternatives. When scientists face underdetermination, they must choose what to believe or whether to suspend judgment.

Because of this unavoidable uncertainty, scientists must decide how much evidence to require before endorsing a theory or hypothesis (or before rejecting a theory or hypothesis). Safety is very important to us, whether for drinking water or medications, so toxicology tests must have a high bar for success. There is a lower bar for deciding whether a new drug is more effective than an already available drug. Scientists also must decide how to represent scientific uncertainty to the public. In 1988, climate scientist James Hansen declared that climate change, global warming, was occurring. He described that as a decision based on weighing “the costs of being wrong to the costs of not talking.” There was already enough evidence for Hansen to be relatively confident in his choice to speak up. Decades later, of course, there is now incontrovertible evidence of climate change.

This introduces a fifth category of values’ legitimate influence on science, regarding how scientists, journalists, and others who communicate scientific findings to the broader public should talk about those findings. As Elliott stresses, this isn’t just a decision to be accurate. Scientific findings also can be discussed in their relationship to previous findings, their potential social effects, or—picking up on the point just above—their level of certainty. This framing influences whether and how the public will engage with research, and this is a choice not dictated by scientific methods but by scientists’ and society’s priorities.

So, what scientists should study, how they should study it, what they aim to accomplish, how much evidential support should be required, and how scientists should communicate their results all depend on moral considerations—on values. These are legitimate influences of values on science. Recognizing these roles for values in science is crucial. This enables us, as a society, to critically assess what values are employed at each of these junctures. The influence of values on science can be problematic or even nefarious if the wrong values are employed at any one of these stages. Figuring out the right and wrong values is tricky, and it is not a matter for scientists alone to decide. Instead, this is an issue that needs to be engaged with broadly in our society.

Examples of problematic values influencing science are, unfortunately, very easy to come by. Here’s one. In 2017, the US president Donald Trump proposed that NASA resources should be dedicated to exploring the solar system instead of to climate change research. This research priority—a decision about what to study—reflects the values endorsed by a small but vocal contingent of politicians in the US. Choosing not to fund climate change research amounts to deciding that knowledge about the rate and impact of climate change is relatively unimportant. Space exploration is important! It, too, should be funded. But because climate change is already having disastrous effects on populations, the environment, and economies across the world, and because the long‐term costs of ignoring it will be disastrous, pulling funding from NASA’s earth science division in order to avoid investigating climate change and its effects upheld the wrong priority.

We have suggested that science doesn’t have to be free from values to be trustworthy and objective. What matters is that values influence science in the right ways and that science effectively resists the influence of harmful, unethical values. Values, even good values, shouldn’t play the wrong roles in science; we should never decide a theory is true simply because we wish it were true. Further, the wrong values shouldn’t influence science, even through the proper channels. To better understand how science earns its trust and objectivity, it’s important to acknowledge the many roles of social and moral values in scientific reasoning and to critically examine the values that influence our science. By doing these things, we can clarify what values should influence science, and in what ways.

##### EXERCISES

13.13 Recall: Define the value‐free ideal for science and describe what is correct about it and what is incorrect about it.

13.14 Think: Describe an example of when values have influenced science in an illegitimate way. (Your instructor might ask you to take an example from this section or to come up with a different example.) Then diagnose what went wrong: what was wrong about the values or the nature of their influence, and what was the detrimental effect to science?

13.15 Recall: List the five ways discussed in this section in which values legitimately influence science. Give an example of each.

13.16 Think: Describe the value-free ideal of science. Then, summarize the view of how values can legitimately factor into science. In your view, does that view of values’ influence violate the value-free ideal, or is it consistent with that ideal? Give an argument in support of your answer.

13.17 Apply: Suppose you are working for an NGO (nongovernmental organization) on the task of measuring poverty levels across countries. For each of the following decisions, describe at least two ways to proceed, and say how values are relevant to making the decision.

- a. Which countries will you include in the study?
- b. How will you define and measure poverty?
- c. What extraneous variables will you take into account?
- d. How will you make comparisons across countries?
- e. How will your results be publicized?

13.18 Apply: Look back at the case of climate change discussed in Chapter 1. Identify at least five ways in which values are likely to have affected that research and describe how those values have impeded or promoted scientific knowledge of climate change.  

### 13.4 CHANGES IN SCIENCE AND NEW CHALLENGES

After reading this section, you should be able to:

- Describe the move toward ABC research in the 21st century and what remains unchanged
- List three challenges to science’s capacity for self‐correction related to incentive structures and sources of funding
- Characterize the current challenges of diversity and public communication in science

#### Changes in 21st century science

Antireductionist, big, and corporate. This is the distinctive new “ABC” of scientific research in the 21st century. ABC research investigates complex phenomena at multiple scales (antireductionist), capitalizes on big collaborations between many scientists with diverse expertise and big data (big), and involves business partnerships with private corporations (corporate). An example is proteomics, which is the study of how proteins influence organisms. Proteins, the building blocks of organisms, are complex molecules that play many vital biological functions. These functions depend on proteins’ physical shapes. Proteins acquire their distinctive shapes when the long chains of hundreds or thousands of smaller molecules composing them, called amino acids, fold into a wide variety of three‐dimensional physical structures.

Since the discovery of the structure of DNA in 1950s, one of biology’s grandest challenges has been the problem of protein folding. This is the problem of determining the 3‐D shape of the proteins in an organism from proteins’ amino‐acid sequence. Unlocking the mystery of how proteins fold is key to preventing and treating many diseases, like cancer; to understanding how life emerged on Earth and how organisms develop; and to many bioengineering applications. This is not just a very important problem; it is also a very hard problem. For any organism, the number of possible amino acid sequences and proteins is very large, and any given sequence of amino acids might fold into a huge number of different 3‐D structures. So, it has been difficult, if not impossible, to tackle this problem with traditional experimental methods.

A machine learning tool called AlphaFold, first developed in 2018, has been a game‐changer in the field of proteomics. Developed by the Google‐owned firm DeepMind, AlphaFold leverages deep‐learning artificial neural networks trained on big data sets about hundreds of thousands of experimentally determined protein structures to predict the shape of thousands of other proteins, in organisms from bacteria to humans, from their genetic sequence. Its predictions are surprisingly accurate. AlphaFold has some limitations—for example, it is not designed to predict the effects of mutations on a protein’s structure—but it is already changing the field of proteomics. It saves biologists a lot of time‐consuming manual labor, so it accelerates research. It can also open new avenues of research, as it makes available new biological hypotheses and interpretations.

Research relying on AlphaFold exemplifies ABC research in its antireductionist approach to studying protein folding in all its variety in an open‐ended, exploratory way; by involving many scientists with diverse expertise, as well as big data methods; and by relying on corporate partnership in producing needed technology. Of course, not all contemporary scientific research fits this pattern, and it’s more relevant to some fields than others. But ABC research is a good characterization of recent trends in scientific research nonetheless. Let’s look at each of these features.

Reductionist methods attempt to account for a system by considering the behavior of its fundamental components, explaining even complex features as the result of component parts. It’s increasingly clear that this approach is inadequate to account for complex, possibly chaotic, systems such as the Earth’s weather and climate; the economic, cultural, and political behaviors of societies; and the workings of the brain. The same goes for the intricate dynamics of protein folding. Antireductionist approaches grapple directly with complexity, employing a variety of methods and approaches from multiple disciplines, often including big data techniques, to probe how networks might self‐organize, what surprising patterns exist, and how systems flexibly adapt to different circumstances. Proteomics and other “omics” disciplines, like genomics, exemplify this anti‐reductionism. And even in fields that fit this model less closely, some techniques employ antireductionist methods.

ABC research is also big. Scientific research has become highly collaborative and ever hungrier for data and computing power. For example, the scientific article first Introducing AlphaFold had more than 30 authors. Each of these authors brought specialized expertise to the research, from machine learning and software engineering to molecular and system biology. Studies in fields like particle physics, genetics, and medicine can feature even larger collaborations, among thousands of scientists who together co-author a single peer-reviewed paper. Running a study in these fields can be like running a Hollywood movie. It requires specialized competences and well-defined roles in a team pursuing an overarching research goal. Large collaborations also typically involve sophisticated equipment and large data sets. And, as we just saw, big data and computational approaches also are made necessary by embracing antireductionist approaches.

#### Box 13.2 Co-authorship in large collaborations and with AI

Pick any recent issue of a scientific journal. Most articles you’ll find will list several co-authors, possibly hundreds or even thousands. The co-authors of a scientific paper are often from different countries and based in different institutions. They have different disciplinary backgrounds, so different co-authors may not fully understand other co-authors’ contributions. The research sometimes involves complex methods or instruments, whose workings may not be transparent to all collaborators. Increasingly often, scientific authors also rely on AI tools such as large language models, for example ChatGPT, for generating and editing text. In a few cases, AI chatbots have also been credited as co-authors of published research. But what if a large collaborative project, where expertise and responsibility are decentralized and distributed among several individuals and even AI tools, produces a published research article introducing a patentable new discovery? Or containing a mistake? Who deserves credit for the discovery or who should be held accountable for the mistake? And can an AI be a genuine co-author? These questions are important—and difficult—to answer. Co-authors are those who make a significant scholarly contribution to an article and who publicly agree to be legally, epistemically, and morally accountable for the published research. This is clear enough. But questions about co-authorship, credit and blame, and accountability become murkier with large collaborations, especially with the advent of AI tools, as there is no single, universal norm for how co-authorship should be determined in collaborative work.

Finally, ABC research is corporate. Large-scale collaborations geared towards understanding complex phenomena can also benefit from involving private corporations. This isn’t inevitable. Most scientific research is still conducted by researchers based at universities and funded by governments and other public institutions. But, there is a trend toward scientific research led by teams of scientists based at corporate research labs like Google DeepMind. With the emergence of machine learning and artificial intelligence, an increasing number of scientists have been recruited from universities to big companies like Amazon, Meta, Google, Tesla, and Uber. The same trend applies to smaller firms and start‐ups, especially in the biotech and food sectors.

The declared mission of corporate science is sometimes basic research, sometimes innovation, sometimes profit. The complicated interplay of these aims has contributed to the discovery of life‐saving drugs, smartphones, and electronic vehicles. It can also boost research in an entire field by making valuable data sets and methodologies openly available to all, as in the case of AlphaFold, where the researchers at DeepMind have made openly available their data sets and computer code. But the relationship between science and corporations is complicated. This foregrounds challenges like the corruption of science from a motive of profit rather than pursuit of knowledge and how patentable data and methodologies should be shared.

Again, not all contemporary scientific research fits this model of antireductionist, big, and corporate. Reductionist approaches remain valuable in numerous research projects; not all scientific research is or should be collaborative; and much research proceeds without influence from corporations or clear application to industry. Note also that, even in ABC research, big data and machine learning tools like AlphaFold are not likely to replace human scientists. Science’s power consists, at least in part, in bringing to bear new ideas in creative ways, making judgment calls about how research should proceed, and looking beyond correlations to seek explanation. In many instances, those aspects of science are best conducted by human intellects.

#### Challenges facing science

Scientific knowledge is worthy of trust due to its characteristics outlined in Chapter 1 — especially its capacity for self‐correction based on evidentialism and social structure, and the many methods and patterns of reasoning used to find evidential support for hypotheses and theories. We saw in Chapter 1 that science’s capacity for self‐correction requires scientists’ openness to criticism and dissent, their sincere and transparent communication of their results and uncertainties, and scientific communities’ welcoming of diverse perspectives. Trustworthy scientific knowledge is produced when scientists’ judgments are critically and openly assessed in light of other data, competing interpretations, and alternative possibilities.

Yet this process of collaboration and criticism, and thus science’s capacity for self‐correction, currently faces significant challenges. Some of these challenges relate to the incentive structure in science and how it shapes scientific findings in ways that can undermine trustworthiness. Facing up to these challenges requires us to think carefully about the scientific process, the role of incentives in shaping that process, and what values are thus finding their way into science.

First, scientists face pressures that make them more likely to focus only on research that will lead to surprising, new results. As we have seen, science is a social practice that occurs in institutions like universities and national research centers. Scientists are professionals who get paid for teaching and for doing research. But university salaries are, in most cases, not enough to fund scientific research. Scientists need extra money to pay for scientific instruments and lab equipment, for experimental participants, and for their assistants. This extra money is generally awarded by public agencies like the ERC (European Research Council) in Europe and the NSF (National Science Foundation) and NIH (National Institute of Health) in the US. The competition is fierce: every year the number of applicants for funding grows, while, partly due to budget cuts, the number of available awards shrinks.

Scientists’ ability to secure grants determines their career prospects. And their chance of securing grants depends on their quantity and quality of publications, frequency of citations, previously awarded grants, and the public attention they are able to attract. “Publish or perish” is the phrase coined to capture the increasing pressure in science to rapidly and continually publish research articles in order to sustain one’s career.

The competition for space in prestigious journals is also fierce; many journals reject over 90% of the articles submitted. And journal editors usually prefer to publish novel results that support an exciting hypothesis rather than negative results, even if they are robust and well documented, or studies replicating earlier findings. The tendency to publish surprising, new results more often than negative results, replication studies, and exploratory work is called publication bias.

Publication bias is common in all scientific journals but especially strong in the most prestigious journals. Consequently, scientists have a strong incentive to produce surprising, positive results. Their careers literally depend upon it! So, this is where scientists tend to put more of their attention, compared to writing up negative findings, replicating or assessing previous results, or even conducting preliminary, exploratory investigations.

Publication bias, combined with the scarcity of resources and employment opportunities, generates a challenge to science’s capacity for self-correction. For one thing, science’s openness to criticism depends on researchers publishing negative findings and attempting to replicate existing studies to see if the evidence holds up. Replication of previously published studies can increase the credibility of scientific claims when the supporting evidence for these claims is reproduced. When findings are not replicated, this can improve experimental designs or data analysis or even give scientists reason to rethink accepted theories. So, a disincentive from publishing negative findings and conducting replication studies undermines self-correction and the accumulation of trustworthy knowledge across science.

The scientific research associating specific foods with cancer risk, for example, may be seriously distorted by a lack of attention to replication. In Chapter 9, we discussed how statistically significant associations with cancer risk have been claimed for most food ingredients, from beef to tea. Careful analysis of this literature highlights that many published studies report implausibly large effects, even when the actual evidence is weak and effect sizes are small. Publishing negative results and greater emphasis on replicability would improve the internal and external validity of research about how different foods influence cancer risk.

Second, the incentive structure of current science also negatively impacts scientists’ communication of their results. The emphasis on producing exciting, publishable results may lead scientists to cut corners in how experiments are designed and how data are analyzed and presented. For example, whether a conscious decision or not, scientists may not randomize group assignment in their experiment or may not control for some known confounding factors. Another common shortcut is data dredging, where data mining techniques are used to uncover patterns in the data that support a hypothesis not under investigation. Data dredging increases the chance of a type I error (see Chapter 10), making it more likely that the endorsed hypothesis is wrong.

Relatively few studies report effect sizes and measures of uncertainty in a transparent way, so it can be hard for others to assess the quality of a study.

Third, science’s capacity for self‐correction and thus its trustworthiness can be compromised by the financial interests funding scientific research. Fierce competition in academic science also is leading scientists to abandon academic research for jobs in industry. IT, AI, and pharmaceutical, chemical, and agricultural industries are hiring more and more scientists, often with better pay and greater job security. This raises another worry about sincere and transparent communication of scientific results. Being funded by a private company to carry out research may pose conflicts of interest, introducing funding bias. Funding bias is when researchers distort the results or modify conclusions of their study due to pressure from the study’s funders. This can happen through the ways in which values influence science—what to study and how, what the aim is, how to handle uncertainty, and how to present the findings. This can also happen via intended or unintentional improper influence on data or methods. Regardless, funding bias leads to corporations having outsized influence on the nature of our scientific knowledge and, in some cases, even misleading the public with bad information.

Another challenge to science’s trustworthiness relates to diversity of ideas and of practicing scientists. Diversity in scientific approaches fosters science’s capacity for self‐correction. But the institutional structure of contemporary scientific inquiry has reduced incentives for and freedom to pursue research challenging existing scientific ideas or moving in new directions. This has fostered increasing specialization in the sciences, and it has also shielded popular theories and methods from being challenged by competing, and perhaps better, theories and methods. Further, as we have seen earlier in this chapter, diversity among practicing scientists—in their social identities, worldviews, and more—is also important for science’s capacity for self‐correction. Yet the diversity of professional scientists remains limited.

Another challenge for science’s trustworthiness relates to public communication. Too much science is inaccessible to the general public. Scientific studies get published by for‐profit journals, and these journals typically put articles behind pricey paywalls. Academic institutions pay for their faculty and students to have journal access, but those without institutional affiliation are left without easy access. By the time science is reported in newspapers and popular magazines, it is often characterized inaccurately and misleadingly, full of hype and exaggeration. This too is due to an incentive structure, this time for journalism: media outlets are rewarded for splash and clicks, not for careful accuracy. This can fuel serious misunderstanding of scientific findings.

In this book, we have painted a picture of science as fallible, but with a formidable set of tools to help in the discovery of knowledge. Some scientific knowledge has had dramatic practical importance—just think about the outstanding progress of the medical sciences and of computer science and AI. Other knowledge regards fascinating aspects of the faraway universe and the strange behavior of microparticles. The ability of science to produce trustworthy knowledge requires openness to criticism and dissent, the pursuit of meaningful questions, and the communication of results in a sincere and transparent way. Only by ensuring these features are maintained and strengthened can science be self‐correcting, generate objective knowledge, and thus deserve our trust.

# EXERCISES

13.19 Recall: Describe three ways in which science has changed in the 21st century. Then, describe three important ways in which science is the same, even with these changes. For the second part of this question, you may want to consider topics from earlier in the book.

13.20 Think: Describe how big data and machine learning approaches are used in science. How transformative do you think these approaches will be for scientific methods and accomplishments? Provide justification for your response in 2–3 sentences.

13.21 Recall: List five current challenges for science described in this chapter. For each, indicate how it threatens science’s objectivity and/or public trust in science.

13.22 Apply: List five potential ethical problems arising from scientific research funded by the pharmaceutical industry. For at least three of these problems, describe a concrete action to address that ethical problem that could be taken by government, pharmaceutical companies, or some other party.

13.23 Apply: Choose a current or recent example of societally important scientific research. Describe the nature of scientific uncertainty and what kinds of action had to be taken even with this uncertainty. Describe how social, economic, and moral considerations might have factored into the decision of how to proceed.

13.24 Apply: In recent years, there have been several retractions of published scientific articles that have captured the world’s attention. In 2015, it was the retraction of a paper about gay marriage that was initially published in the prominent scientific journal Science. Read the description of this case on Retraction Watch, then answer the following questions.

1.  What risks do people who report misconduct in science (whistleblowers) face?
2.  Were human subjects “harmed” in this case, and if so, how?
3. Describe how data management issues influenced this case.
4. Describe how authorship issues influenced this case.
5. Does this case raise any conflict of interest?
6. What issues does the case raise about collaborating with others?
7. Describe how replication issues influenced this case.



##### FURTHER READING

For a readable account of the wide variation of sex and reproductive strategies in the animal kingdom, see Roughgarden, J. (2004). *Evolution’s rainbow*. University of California Press (reprint 2013).

On participation in science and relationship to the public, see Potochnik, A. (2024). *Science and the public*. Elements in Philosophy of Science, Cambridge University Press.

For an introduction to the roles values play in science, see Elliott, K. (2017). *A tapestry of values: An introduction to values in science. Oxford University Press and (2022). Science and values*. Elements in Philosophy of Science, Cambridge University Press.

On complexity, see Mitchell, M. (2000). *Complexity: A guided tour*. Oxford University Press.

