## CHAPTER 3 Scientific experiments  

### 3.1 THE NATURE OF LIGHT AND EXPERIMENTAL DESIGN

After reading this section, you should be able to:

- Define experiment and provide examples
- Describe three ways in which existing scientific knowledge shapes experiments
- List five features of experimental design and identify them in an example experiment

#### Experimenting on light

In Chapter 2, we discussed how many of the successful recipes for science involve three ingredients: hypotheses, expectations, and observations. Scientific experiments provide scientists with a structured way to make observations and compare them to what we would expect to observe if the hypothesis under investigation is true.

An experiment is a type of empirical investigation where researchers perform an intervention that changes some feature of a system and observe the effects, with the aim of understanding how the system works or why a certain outcome occurs. Ideally, an experiment changes a system in such a way that the effects depend only on the intervention rather than on other possible factors. For example, by giving the plants on one windowsill in my apartment different types of fertilizer and observing what happens, I can know that the fertilizer is what’s making a difference to the plants’ growth. This is how experiments enable us to figure out what would happen to a system if some of its features were different—for example, what would happen to my plants if I gave them urine as fertilizer?

Being able to figure out what would happen if something were different matters for policymaking and applied research—for example, a company might decide to invest in urine-based fertilizers, or governments may incentivize the use of urine-diverting toilets for recycling waste, if it turned out that urine was an excellent fertilizer.

To begin to explore the main aspects of experiments, let’s consider the nature of light. Have you ever seen how a glass prism can make little rainbows appear around a room? When sunlight passes through a piece of glass, the white light is separated into different rainbow colors. Why does that happen? Where do those colors come from?

The nature of light and its relation to the color spectrum visible in rainbows have been studied for millennia. In Chapter 1, we mentioned Ibn al-Haytham (Latinized as) Alhazen, who during the Islamic Golden Age advanced the scientific understanding of vision, optics, and light. Through experiments using lenses and mirrors, al-Haytham showed that light travels in straight lines. From dissections, he began to explain how the eye works and began synthesizing the medical knowledge of previous scholars. In particular, al-Haytham demonstrated that light is not produced by the eye, as some theories had claimed, but instead that it enters the human eye from the outside. This research formed the basis of scientific knowledge about light.

In the 17th century, many scientists—or “natural philosophers,” as scientists were called then—believed in what we might call the modification hypothesis of light. They thought that sunlight is essentially white, and that the spectrum of colors we see from a glass prism is caused by the impurities of the glass modifying the light. Isaac Newton was unconvinced. He hypothesized instead that white light is made of several colors, and that passing sunlight through a glass prism causes those colors to separate and become visible. If this hypothesis were true, then the modification hypothesis would be wrong: the impurities of the glass are not the cause of the rainbow colors we observe from prisms.

Newton performed several experiments to test his hypothesis. In one experiment, he darkened his room and bored a small hole in the window shutters so that only a thin beam of light could enter the room, casting a white circle of light on the wall. Then Newton placed a glass prism in the beam. A rainbow of colorful light appeared on his wall. This observation was consistent with the expectations of both the modification hypothesis and Newton’s alternative hypothesis that white light is a mixture of colors. Both hypotheses lead us to expect that a beam of light travelling through a glass prism will produce different-colored bands. One thing was intriguing though: the shape of rainbow light was not a circle, as the white light had been, but oblong.

Then, Newton added a second prism to the path of the light. If the modification hypothesis was true—he reasoned—you would expect that the impurities contained in the two glass prisms would continue to modify the sunlight and just spread out the color spectrum further. But when the spectrum of colored light passed through the second prism, it recomposed back into white light! Because the modification hypothesis, if true, does not lead us to expect this observation, Newton concluded that the Modification hypothesis was probably false. This result showed that white light could be composed of a rainbow spectrum: Newton’s experiment had made this happen! This finding also raised new questions. If light is a spectrum of colors, what’s the nature of these colors? Are they particles of some sort? What makes them different colors? And why do the different colors spread out when they travel through the prism, making the light oblong instead of round? It would take more experiments performed by Newton and several other scientists to answer these questions and lead us to better understand the nature of light.

#### Experimental design

As Newton’s experiments illustrate, experiments involve much more than simple observation. Experiments are strategically designed to enable the expectations drawn from a hypothesis to be tested.

An important feature of any experiment is its material aspects. Performing an experiment involves physical, concrete objects. While the experimental setup in Newton’s experiments on light involved only cheap glass prisms, pencils, and notebooks, many present-day experiments require more expensive technologies, including specialized instruments, biological samples, chemical reagents, standardized questionnaires, computers, software for data analysis, and so on. All this apparatus costs money, which raises questions about how funding should be distributed among experimental research projects. For example, should we spend billions of dollars on a special superconducting collider for experiments in particle physics, or should funding agencies distribute money to prioritize several small-scale cheaper experiments in other fields?

Another important material aspect of experiments is what is being experimented upon. Experiments can focus on humans, non-human animals, or inanimate objects; these are the subjects of the experiment, also called experimental entities or participants. Human experimental participants are typically paid for participating in an experiment, while non-human animals for experimental testing often need to be bought, fed, and trained. Some inanimate objects on which certain interventions are performed are cheap to obtain or free, such as the rays of sunlight on which Newton experimented. But other objects studied in other experiments, such as rare metals, are hard to obtain and expensive. Experiments on humans vs. non-human animals vs. inanimate objects present different challenges and opportunities, which is discussed in section 3.3.

##### Box 3.1 Ethics and data management in experiments

Ethical evaluation is an integral part of contemporary scientific practices. If researchers want to run an experiment involving humans or non-human animals, typically they have to fill out an Ethical Clearance, Data Management and Protection form, where they describe the aim of the experiment, how it will be performed, what data will be collected, how the data will be analyzed, where The data will be stored, for how long, and who can access them. The researcher fills out and submits this form to the Ethics Committee of their institution. In the US, this is the Institutional Review Board (IRB). This committee includes other researchers and ethicists tasked with evaluating potential ethical and methodological issues with the proposed research. The Ethics Committee must give clearance before the research begins. The aim is to uphold scientific integrity and methodological soundness—especially when personal data are collected, such as sensitive demographic information, or when invasive interventions are performed.

Before participating in an experiment, subjects must be informed of the research’s potential risks and benefits, and they must explicitly consent to be part of the experiment and grant the researcher the right to collect and use their data for specific scientific purposes. Ethical clearance and data management and protection is a recent innovation. Many (in)famous experiments in medicine and social psychology, such as the Tuskegee Study in the 1930s, Harry Harlow’s monkey studies in the 1960s, and Philip Zimbardo’s Stanford Prison Experiment in 1971, did not receive ethical clearance and could not be performed nowadays.

Where an experiment occurs and over what period of time can also be important features of the experimental design. Newton’s experiments on light took place in his room at Trinity College, Cambridge UK, around 1670. Many present-day experiments occur in laboratories located in universities and hospitals or take place in the field, that is, in settings like farms, subway stations, and forests. Newton’s experiments on light had a short duration; other experiments can last years, such as present-day experiments in high-energy physics at the European Organization for Nuclear Research (CERN) in Geneva, Switzerland, where a very expensive and large superconducting collider called the Large Hadron Collider is used to accelerate and collide subatomic particles to study the nature of the fundamental constituents of matter and light.

Whether an experiment takes place in a laboratory or the field, their location and setup are always background conditions that can influence the data collected. Background conditions are the physical, technological, and social aspects of an experiment or study. The room at Trinity College where Newton performed his experiments had a certain ambient lighting, temperature, and humidity. The angle at which sunlight hit the room’s windows varied by time of day and season. Prisms, the instruments Newton used, were not commonly thought of as scientific instruments in the 1660s and so were sold simply for their entertainment value. As a result, they were irregular in both size and composition. These features were all in the background of Newton’s experiments. For his experiments to produce evidence against the modification hypothesis, Newton needed to show that none of these background factors were responsible for the results.

Experiments are designed to produce data. Data was defined in Chapter 2 as public records produced by observation or by some measuring device. Data provide evidence in favor of or against a hypothesis. Newton’s data consisted of records in a notebook of the effects of passing a beam of sunlight through one or more glass prisms. For physicians, the results of blood tests and testimony about one’s medical history can both count as data. Fossils, tracks, and recordings of the chemical features of mammoth tusks and of rocks in different locations all can count as data for a paleontologist. Climate scientists collect data from things like glaciers, oceans, and the atmosphere—for example, glaciers’ mass balance, sea surface temperatures, and the atmospheric pressure at sea level.

Another feature of experimental design is who carries out the experiment. A scientist may conduct an experiment alone, but collaborative experiments are common in contemporary science. Most collaborative experiments involve scientists with different scientific expertise who rely on one another’s expertise. Experiments at CERN, for example, are highly collaborative, run by hundreds of scientists and engineers from all over the world, each of whom brings some specific expertise to bear.

Even when an experiment is run by a single lab or an individual scientist, the broader scientific community shapes the experimental design. Communities of scientists, represented by scientific institutions and societies, determine protocols to be followed in experimental design and data analysis. These protocols include ethical guidelines for what sort of experiments are permissible, how experimental participants—humans or non-human animals—should be treated, and how data should be managed. As it happened, the Royal Society—the learned society for science of which Newton was a member—criticized his results, suggesting that the prisms’ bubbles, veins, and other impurities caused the light to become colored as it passed through and that the modification hypothesis could account for the results of his experiments.

##### EXERCISES

3.1 Recall: Define experiment and give two examples of experiments.

3.2 Apply: For each of the two example experiments from Exercise 3.1, identify the hypothesis or hypotheses under investigation, the expectations for the experiment based on the hypothesis or hypotheses, and important features of the experimental design.

3.3 Recall: What is the modification hypothesis of light? Describe Newton’s one-prism experiment and his two-prism experiment. For each, say what evidence it provided that challenged the modification hypothesis.

3.4 Recall: Describe three ways in which existing scientific knowledge shapes experiments. Illustrate each with an example from Newton’s experiments on light.

3.5 Recall: List five features of experimental design. Identify each feature of experimental design for both Newton’s prism experiments and experiments at CERN, the Large Hadron Collider.

3.6 Apply: List five features of experimental design. Find an example experiment described in a research article (or your instructor may provide you with an example). As best you can, identify each feature of the experimental design from what is said in the article. Then, describe how the experiment relies on existing scientific knowledge.

### 3.2 THE POWER OF EXPERIMENTS: INTERVENTION AND CONTROL

After reading this section, you should be able to:

- Define intervention, independent variable, dependent variable, and extraneous variable and indicate the role of each in a perfectly controlled experiment.
- Indicate how defining expectations and collecting data can introduce confounding variables.
- Describe two strategies of variable control: direct and indirect.

#### The perfectly controlled experiment

Experiments have some ingenious features that make them a powerful way to gain scientific knowledge. To appreciate those features, it will be useful to start by describing an ideal experiment, even if real experiments usually deviate from this ideal. In an ideal experiment, experimenters perform an intervention that changes only one single feature of a system or situation while all other features remain the same. As a result of all the other features being unchanged, scientists know that any change in the system or situation is due only to the intervention.

That’s the basic idea, but introducing some technical vocabulary will help make this precise. A variable is anything that can change, vary, or take on different values. For example, the number of books you read in one year, people’s height, and the temperature in your hometown are all variables, since these are all things that can change over time or vary in different people or places. The value of a variable is just the particular state of the variable in some instance. For example, the value of the variable number of books you read in 2024 might be 0, 12 or 56; the value of the variable Matteo’s height is now 1.85 meters (6 feet); and your hometown temperature might have the value 62° Fahrenheit (16.67° Celsius) one summer evening and 92° Fahrenheit (33.33° Celsius) the next evening.

In experiments, there are three types of variables, distinguished by the roles the experimenters want them to play. An independent variable is a variable that’s changed or observed at different values in order to investigate the effect of the change. A direct manipulation of the value of the independent variable is called an intervention. For example, the independent variable in Newton’s experiment on light was the number of glass prisms through which the beam of sunlight passed; this variable had the value of 0, 1, or 2 in the experiments we described earlier.

A dependent variable is a variable researchers measure for changes after they intervene on the independent variable. The researchers anticipate how the value of the dependent variable depends on, or is affected by, the independent variable. When scientists perform an intervention in an experiment, they do so to investigate how that change affects one or more dependent variables. For example, Newton varied the number of prisms through which sunlight passed (independent variable) and then looked for changes in the color and shape of the light that had passed through the prisms (dependent variables).

The goal of an experiment is to isolate the relationship between an independent variable and one or more dependent variables. This requires controlling all extraneous variables.

#### Extraneous variables

Extraneous variables are all other variables besides the independent variable that may influence the value of the dependent variable. In Newton’s prism experiments, extraneous variables included bumps and impurities in different prisms, the time of the day, the angle at which a beam of light hits the prism, the ambient temperature, and much more. If you are experimenting with a new homemade fertilizer to find out how it affects the growth of your plants, then the amount of light, water, soil quality, ambient temperature, and more are all extraneous variables.

In an ideal experiment, recall, experimenters intervene on one feature of a system or situation (the independent variable) while all other features (extraneous variables) remain the same, so they know that any change (dependent variable) is due to the intervention. Keeping fixed the values of all extraneous variables is known as controlling the extraneous variables. More precisely, variable control is creating conditions such that no extraneous variable can change the value of a dependent variable during or as a result of an intervention on the independent variable. In a perfectly controlled experiment, any change in a dependent variable can only be due to the intervention on the independent variable. This isolates how the independent variable affects the dependent variable(s). In Newton’s prism experiments, his goal had been to control the conditions of the light beam so carefully that any changes to the light (color, shape, etc.) could be due only to the prism(s).

#### Controlling variables

A perfectly controlled experiment is simple to describe, but it’s difficult even to get close to this ideal in practice. Many extraneous variables can influence the dependent variable in a given experiment, and some may be hard to control or even to identify. When you investigate the effect of a homemade fertilizer on your houseplants’ growth, you need to somehow ensure no other conditions—amount of sunlight, season, warmth in your home, humidity, soil quality, the prior health of the plants, different growth rates in different kinds of plants, etc.—are instead responsible for any changes in growth.

When extraneous variables are not controlled and affect the relationship between the independent and dependent variables, we call them confounding variables, or confounds. Confounding variables can undermine researchers’ ability to draw conclusions about the influence of the independent variable. So the goal of variable control is to avoid any confounding variables.

##### Table 3.1 Types of variables and their use in experiments

| Type of Variable     | Use in Experiments                                           |
| -------------------- | ------------------------------------------------------------ |
| Independent variable | An intervention is performed upon the independent variable   |
| Dependent variable   | Dependent variable(s) are measured for changes after an intervention |
| Extraneous variable  | Extraneous variables are controlled directly or indirectly so they do not vary during an experiment |
| Confounding variable | An extraneous variable that was not controlled and may have interfered with the relationship between independent and dependent variables |

There are two basic strategies of variable control: direct and indirect.

**Direct variable control** is when experimenters hold extraneous variables at constant values during an intervention. This is why Newton ran his experiments at the same time of day and in the same darkened lighting conditions. Keeping the values of those variables constant ensured that they didn’t change the light’s behavior. Newton also attempted to directly control the confounding variable of air bubbles and other impurities in the prisms by using higher-quality prisms. The carefully managed conditions in today’s laboratories help scientists to directly control many variables. For example, there is a standard temperature and pressure used for laboratory experiments, abbreviated STP. In experiments conducted with the Large Hadron Collider at CERN, scientists use sophisticated technologies to keep many variables under direct control, such as the magnetic fields and temperature in the collider.

Some extraneous variables are difficult to hold constant or even to identify as potentially relevant. For these variables, indirect variable control is best.

**Indirect variable control** is when experimenters allow extraneous variables to vary but ensure that variation is independent from the value of the independent variable. The key to indirect variable control is to study multiple systems, situations, or groups, all with the same variety of features and facing the same range of conditions other than the independent variable. Then, even though many variables vary, the value of the independent variable is the only systematic difference between them. In this case, any differences in the dependent variable between the systems, situations, or groups must be due to the difference in the independent variable. You might not be able to keep the humidity or temperature of your home exactly the same over days or weeks, and you certainly can’t control the weather. But you can put two plants of the same kind on the same windowsill, give them the same amount of water (these are direct variable control), and let the other conditions the two plants encounter vary. Those conditions should affect both plants about the same.

But what if one of the two plants just happens to be heartier or quicker growing than the other? Indirect variable control often employs groups to also include variations across individuals. So, instead of studying two plants, perhaps you plant ten seeds from the same seed packet, five into each of two pots. You place both pots on the same windowsill and water both pots the same amount, at the same time. Perhaps you even switch which side of the windowsill each is on once a week. After three weeks, you thin the plants to the three tallest in each pot. Then, even though conditions for the plants are changing over time and you don’t know if some of the plants will grow larger than others, the group of plants in each pot should experience about the same range of conditions.

With indirect variable control, the only systematic difference between groups is the value of the independent variable. One group, the experimental group, receives the intervention to the independent variable, or experiences the intended value of the independent variable. The other group, the control group, does not receive the intervention but experiences other value(s) of the independent variable. As you can probably guess by now, of the two pots of plants, one should be treated with your homemade fertilizer, while the other should not. What happens to that second pot of plants, your control group, depends on what you want to investigate. Do you want to know how your homemade fertilizer compares to no fertilizer at all, or to the fertilizer you used to buy from the store? What value you set the independent variable to in your control group determines what you will learn about the intervention under investigation.

One common strategy for forming experimental and control groups is randomization, which is the use of arbitrariness or some chance procedure like a lottery to assign experimental entities to experimental and control groups. Randomization is meant to ensure that the two groups are equal in all relevant characteristics except the intervention, since any differences among the experimental entities should vary randomly across groups. This is effectively what we were proposing when we described planting ten seeds from the same packet into two pots—seeds with different characteristics were equally likely to make it into each group. Many scientists, especially in the medical sciences, believe that randomized controlled trials (RCTs) are the gold standard of indirect variable control. But, as we will see later in this chapter and in the next chapter, there are other techniques for managing extraneous variables.

Random group assignment guarantees extraneous variables are not deliberately related to group assignment, and so not related to whether experimental entities experience the intervention. But random group assignment does not guarantee that all extraneous variables vary equally within the two groups. Randomization only ensures the similarity of the experimental and control groups in the limit—only when the experimental subjects are randomly divided in two groups an infinite number of times. In actual randomized experiments, the two groups may have systematic differences simply due to chance. Perhaps, just by chance, all the seeds that went into one pot were able to germinate sooner and grow larger. For this reason, for randomization to be an effective approach to indirect variable control, the groups must be large enough so that large chance differences across groups are very unlikely. Planting five seeds per group is better than just one seed, and planting ten seeds per group (with adequate space to grow) is even better.

#### Clarifying expectations and collecting data

To test a hypothesis with an experiment, clear expectations must be articulated for the outcome of the experiment. These expectations are predictions of the results of some intervention, assuming the hypothesis in question is true. Expectations should be clearly and precisely defined before running the experiment, in a way that makes them easily comparable to the data the experiment will produce. Yet, scientists’ hypotheses can involve broad concepts and ideas that can be hard to know how to test.

Two techniques that scientists can use to generate precise expectations from hypotheses with broad concepts and ideas are operational definitions and cluster indicators. An operational definition is a specification of the conditions when some term applies, enabling measurement. In social science research, for example, wealth might be operationally defined as a household’s combined material assets, as this would capture an important component of material wealth and offer a precise, measurable basis for comparison. But this operational definition also simplifies a complex concept. For instance, generational wealth not yet transferred into a household isn’t considered. Because of this lack of nuance, economists often study wealth using a combination of indicators, such as yearly income, access to education and healthcare, and permanent housing. Such cluster indicators identify several markers of some variable in order to more precisely measure it while not oversimplifying it. Many terms can be defined in multiple ways without one being obviously best, but the choice between different operational definitions and cluster indicators is not arbitrary. This depends on the scientists’ research goals and the details of the experimental setup, and the choice is important. Employing the wrong definition might introduce a confounding variable, such as generational wealth, or it might obscure impacts of the intervention. What if, in your fertilizer experiment, you simply measure plant height, but your fertilizer increases plant longevity or improves flowering?

Data collection is another opportunity for confounding variables. First, this often involves specialized instruments, technological tools or other kinds of apparatus used in experiments, ranging from specialized equipment to surveys. These instruments are a possible source of error—and thus a potential confounding variable. Newton had to convince the Royal Society and other audiences that the data he collected using prisms was legitimate, as prisms’ use in scientific inquiry was not yet broadly accepted. Questions about the reliability of instruments used in experiments still arise. The reliability of an instrument is the extent to which it accurately and consistently measures what it is supposed to measure.

Scientists must calibrate instruments to ensure they are reliable. Calibration is the comparison of the measurements of one instrument (for example, an electronic ear thermometer) with those of another (for example, a mercury thermometer) to check the instrument’s accuracy and adjusting the instrument if needed. In experiments with human subjects, data collection often involves surveys or questionnaires, and these also need to be calibrated and assessed for reliability just as technical apparatus does. A poorly designed question can prime subjects to answer in a certain way, for example, or questions might be ambiguous, eliciting different kinds of responses from different people or unintentionally asking about more than one thing at once.

Calibration and assessment of reliability are ways of directly controlling extraneous variables related to data collection. Another set of extraneous variables that must be controlled during data collection is human expectations. We learned about the observer-expectancy effect in Chapter 1, how a scientist’s expectations can lead them to unconsciously influence the behavior of experimental subjects. For example, it’s well established that the expectation that a medicine will be effective can lead to improved health; this is called the placebo effect. Researchers’ expectations and, for experiments involving human subjects, subjects’ expectations thus need to be controlled or they may become confounding variables.

The strategies of direct and indirect variable control that we have talked about so far don’t help with the extraneous variable of human expectations. To control for this, scientists rely on blinding (or masking), which is when researchers or subjects are temporarily kept unaware of group assignment, hypotheses under test, or other experiment details. Blinding aims to reduce the risk of biased observations by directly controlling the information researchers and/or experimental subjects have access to and, thus, indirectly controlling their expectations. In double-blind experiments, researchers and subjects are both unaware of which subjects are in the experimental and control groups.

##### EXERCISES

3.7 Recall: Define intervention, independent variable, dependent variable, and extraneous variable and indicate the role of each in a perfectly controlled experiment.

3.8 Apply: Review the discussion of Newton’s prism experiments from section 3.1. Identify the two hypotheses under investigation, the independent variable, and the dependent variable(s). Describe the intervention and how Newton controlled extraneous variables. What were the expectations based on each hypothesis? What did Newton conclude on the basis of his experiments?

3.9 Recall: Define extraneous variable and confounding variable. What is the relationship between the two? Why are experiments designed to limit confounding variables?

3.10 Recall: Define direct variable control and indirect variable control. Give three examples of directly controlled variables and three examples of indirectly controlled variables in the fertilizer experiment sketched in this section.

3.11 Think: (a) What is the purpose of having an experimental group and a control group in an experiment? (b) How does division into two groups achieve this purpose, and why is random group assignment important? (c) What are the limitations of this strategy?

3.12 Recall: Describe how defining expectations and collecting data can introduce confounding variables and how each can be controlled.

### 3.3 LEARNING FROM EXPERIMENTS

After reading this section, you should be able to:

- Define internal experimental validity, external experimental validity, ecological validity, and population validity and indicate why each is important
- Analyze how sample selection, sample size, group number, and group assignment influence experimental design
- Describe the challenges that reliance on background knowledge and alternative hypotheses pose to testing hypotheses with experiments

#### Internal and external validity

Laboratories give researchers control over many aspects of an experiment. Depending on the kind of experiments performed, a lab’s design features may include constant temperature, sterile environment, special equipment to produce unusual conditions, or, for experiments with human subjects, carefully selected lighting and furniture, soundproofing, and so forth. Those design features, and the direct variable control they provide, constitute one of the greatest advantages of the laboratory experiment. These features can enable scientists to discover regularities that are not easy to discern in the outside world.

The high degree of control enabled by laboratory conditions brings with it a high degree of internal experimental validity. Internal experimental validity is the extent to which researchers can infer accurate conclusions about the relationship between the independent and dependent variables. This amounts to the absence of confounding variables, achieved by direct or indirect control of extraneous variables. Another advantage of laboratory experiments is that the experimental setup and data analysis can follow standard procedures, which make it easier to assess and replicate an experimental finding.

However, lab research also has some disadvantages. Some phenomena are not easily investigated in a lab. Suppose you are investigating the effects of climate change on large marine mammals, especially the effects of elevated Arctic Ocean temperatures on the deep-diving behavior of narwhal whales. Narwhals—sometimes called unicorns of the sea because of their tusks—can dive as deep as 1.8 kilometers in Arctic waters. To directly investigate this phenomenon in a lab, you will need—for starters—a huge tank of freezing salt water nearly two kilometers deep. Investigating this in the lab is thus all but impossible.

The unusual conditions in a lab that make it easy to control variables also make the lab setting different from the outside world, and that has some disadvantages too. The artificiality of the experimental setting might mean that the results obtained in the lab do not generalize well to real-life settings outside the lab. This is problematic since it’s ultimately the real-world phenomena that we want to know about. Laboratories thus facilitate high internal validity, but potentially at the cost of external validity. External experimental validity is the extent to which experimental results generalize from the experimental conditions to other conditions—especially to the phenomena the experiment is supposed to yield knowledge about.

One component of external validity is ecological validity. Ecological validity is the degree to which an experiment’s circumstances are representative of real-world circumstances. Experimental settings or what subjects are asked to do can be artificial, unlike real-world circumstances, in ways that impact the phenomenon under investigation. One way to enhance the ecological validity of an experiment is to conduct it “in the field,” that is, in participants’ everyday environment outside of the laboratory; such experiments are called field experiments. Field experiments tend to have more external validity than lab experiments because they occur in circumstances similar to everyday circumstances. Their ecological validity is higher as a result.

A downside to field experiments is decreased internal validity. Less influence over the circumstances and the selection of experimental subjects is linked to decreased control over extraneous variables and sometimes a decreased ability to intervene in the desired way. The decreased influence on experimental design also makes it more difficult for other researchers to replicate the experiment. Researchers conducting field experiments may also be constrained in what they can be in a good position to observe or measure, the number of subjects they can involve, and how long they can run the experiment. Many field experiments require special permissions from subjects or from authorities that control access to areas like nature preserves. Uncontrollable events like inclement weather or warfare can also disrupt observation or limit the length of study that’s feasible.

Watch Video 7

#### Samples and groups

Alongside ecological validity, the second component of external validity is population validity: the degree to which experimental entities are representative of the broader class of entities or population of interest. With a representative sample, the experimental entities studied do not vary in any systematic way from the general population. The more representative a sample is of the broad class or population, the more confident scientists can be of the experiment’s external validity.

Here’s an illustration of the importance of population validity. Many clinical trials testing the efficacy and side effects of drugs have been performed only on men, but the results are expected to generalize to women as well. This decreases the population validity of the results, since women and men differ in several medically relevant ways. There is thus relatively limited experimental knowledge about the effects of some drugs on women, and this may have serious consequences for health and medicine. Indeed, some prescription drugs have been withdrawn from the market after they were belatedly revealed to pose greater health risks for women than for men.

One way to increase population validity is random sampling: using a chance method for selecting a sample to investigate from the population (this is not the same as randomization, which relates to group assignment). In a random sample, every member of the population has an equal chance of being selected for participating in an experiment. Unfortunately, hardly any experimental sample of human subjects is randomly selected. Many experiments only involve “convenience samples” like college students or social media users. But neither college students nor social media users are representative of the entire population of any country. Indeed, the criticism has been made of psychological research that almost all has been conducted on “WEIRD” subjects (Western, educated, industrialized, rich, and democratic), which are not representative of people across the world.

**Sample size** is the number of individual sources of data in a study; often this is simply the number of experimental entities or subjects. In section 3.2, we mentioned that indirect variable control requires a large enough sample to ensure chance variation doesn’t differently influence the experimental and control groups. A larger sample size also can improve the sample’s representativeness, simply by including more variation present in the broader population. Of course, this won’t help with variable values that are systematically excluded, like medical trials that enroll only men or psychological studies that enroll only college students in the United States. But, for variables that are included in the sample just by chance, a larger sample increases the values represented.

In general, then, a larger sample size increases the success of indirect variable control, thus increasing an experiment’s internal validity, and increases population validity, thus increasing an experiment’s external validity.

But the advantages of a large sample size must be balanced against the practical disadvantages. Large samples are more difficult to assemble and are more difficult and expensive to manage in the experiment. There are also diminishing advantages to samples beyond a certain size that are not intentionally more representative. It would be a bigger improvement for a psychological study to enroll subjects of different ages and education levels than it would be for the study to enroll 5,000 US college students instead of 1,000 US college students.

Another choice in experimental design concerns how many groups to include in an experiment. So far, we have focused on experiments with two groups: an experimental group and a control group. More complicated experimental designs include multiple experimental groups, each of which experiences a different but related intervention. For example, returning to our imagined fertilizer experiment, we may want to compare our homemade fertilizer both to a commercial fertilizer and to no fertilizer at all. Including multiple experimental groups can be enlightening, and it can lead to surprising outcomes. But this also complicates experiments, making them more difficult to perform, and it makes it more difficult to get an adequately large sample size for each group. Having multiple experimental groups also can make analysis of the results more difficult. For these reasons, experiments are usually performed with as few experimental groups as researchers deem absolutely necessary to get the needed comparative data.

#### Background knowledge and alternative hypotheses

The design of experiments is influenced by existing scientific knowledge. Existing knowledge shapes what hypotheses are developed and what expectations scientists have based on a hypothesis. Due to past research by others, Newton’s experiments presumed that light is a substance that travels from a light source. From Newton’s hypothesis that white light is composed of colors, Newton developed the expectation that a rainbow of light could be recombined into white light—an expectation his two-prism experiment was developed to test. This expectation relies on the idea, part of background knowledge about light, that changes to light can be reversible. Existing scientific knowledge also helps guide scientists’ interpretation of experimental results as evidence in favor or against some hypothesis. For example, the finding that a rainbow spectrum becomes oblong surprised Newton, since he knew from existing research that light typically travels in straight lines.

The reliance of experiments on existing knowledge is unavoidable, but it does create some challenges. What if any of that existing knowledge is wrong? Scientists have to rely on existing ideas to design properly functioning experimental instruments and to know what expectations to draw from their hypotheses. But they also have to rely on properly functioning instruments to test their theories with trustworthy experimental data and on the relationship between hypotheses and expectations to know what conclusions to draw about hypotheses on the basis of experimental data. Indeed, the existing knowledge that informs experimentation could turn out to be wrong.

But scientists have some resources to diminish the risk. First, researchers often have a good sense for what ideas are plausible enough to be trustworthy as the basis for experiments and which are new and risky. Second, over time, researchers refine not just their theories but also instruments and experimental designs. This can involve experimental work in replication or calibration, as discussed in section 3.4. Scientists can conduct an experiment or analyze data using different instruments or techniques to detect any variation depending on instruments or experimental design, called triangulation, and then use this to refine their theories, instruments, and experimental methods.

Another challenge in using experiments to definitively test hypotheses is underdetermination: the evidence may not be sufficient to determine which of multiple hypotheses is true. Consider again the experiment we imagined to test whether homemade fertilizer improves plant growth. Even if you clearly defined expectations if the hypothesis is true (plants receiving the homemade fertilizer grow faster than others), perfectly controlled extraneous variables with your experimental design, and collected data that matched your expectations, the truth of your hypothesis wouldn’t be guaranteed. At the outset of the chapter, we imagined testing the hypothesis that urine is an effective fertilizer, and so let’s suppose that’s the fertilizer under investigation. You take a daily multivitamin: is that the only reason the urine was an effective fertilizer? We can’t know without a new experiment. These kinds of questions are always possible, but scientists can’t think of every possible hypothesis. It’s always possible that some unimagined hypothesis that hasn’t been tested accounts for the experimental results.

How should scientists proceed in the face of underdetermination? One response would be to suspend judgment about which hypotheses should be accepted. But this isn’t an option when we need to build a bridge or design an effective drug. Instead, scientists must diligently attempt to consider alternative hypotheses that might account for the data, testing alternative hypotheses that seem potentially credible. Additionally, hypotheses that fit with the available experimental data are sometimes more or less appealing in other regards; for example, they may be simpler or fit better with other scientific knowledge. These considerations may push us toward one or another hypothesis when the data underdetermine which is true. Ultimately, underdetermination simply requires continuation of the spirit of openness to falsification that we identified as essential to science.

##### EXERCISES

3.13 Recall: Define internal experimental validity, external experimental validity, population validity, and ecological validity. For each, describe its specific importance and how it can be improved.

3.14 Recall: What are the main advantages and disadvantages of a laboratory experiment? How about a field experiment?

3.15 Apply: For each of the following hypotheses, indicate (a) whether you would study it in the lab or in the field, briefly describing why, (b) what steps you would take to control extraneous variables, and (c) whether you are more confident about the internal or external experimental validity of your study and briefly describe why.

- a. Whether peacocks’ colorful trains play a role in their mating success
- b. Whether a new fertilizer improves plant growth
- c. Whether watching a television show about sharing improves children’s ability to share their toys

3.16 Recall: Describe how sample selection, sample size, group number, and group assignment are each important to experimental design. For each, describe the negative effect a wrong choice can have.

3.17 Apply: Suppose you want to test the hypothesis that baseball players who eat pizza every day hit more home runs. Let’s suppose that to test this hypothesis, you want to divide the baseball players of some team into two groups that are balanced in all important background variables that can affect players’ performance. The only difference you want between the two groups is that the members of one group eat pizza every day and the members of the other group do not.

Rank the following four strategies from best to worst for accomplishing this goal:

1. Sit in the clubhouse after a game. The first players who enter the clubhouse are assigned to the group of pizza eaters (the experimental group), while the following players are assigned to the control group.
2. Allocate players born in the first six months of the year to the experimental group and players born in the second six months of the year to the control group.
3. For each player in the team you toss a coin. If the coin lands on heads, then the player is in the experimental group; otherwise, the player is assigned to the control group.4. Scientific experiments
4. Assign all players over 230 pounds to the experimental group and the rest of the players to the control group. Justify each of your rankings by describing how well or poorly you expect that strategy will control the extraneous variables.

 3.18 Recall: Describe the challenges that reliance on background knowledge and untested alternative hypotheses pose to testing hypotheses with experiments. How can scientists manage each challenge?

### 3.4 OTHER USES OF EXPERIMENT

After reading this section, you should be able to:

- Define crucial experiment and indicate three limitations of these experiments’ decisiveness
- Describe the use of experiments in replication and calibration and give examples of each
- Indicate how exploratory experiments differ from experiments to test hypotheses

#### Crucial experiments and replication

Albert Einstein’s theory of general relativity revolutionized our understanding of space and time. While Newton believed that space is a sort of stage on which events unfold, Einstein conceived of space and time as a single interwoven manifold, a fabric of sorts. For Newton, gravity was a force; Einstein instead explained gravity as the curvature of the space‐time manifold. Just as marbles placed on a fabric sheet held in the air bend the sheet around them, massive objects like the Sun warp space‐time in their vicinity. That’s why other objects accelerate toward those massive objects. Einstein’s theory of general relativity leads to testable hypotheses. One of these hypotheses is that light, just like any other form of matter, is affected by gravity. This hypothesis, in turn, generates the expectation that if a beam of starlight passes near the Sun it will bend toward the Sun.

This expectation was first tested on May 29, 1919, when a total solar eclipse blocked out the light of the Sun. A group of scientists led by Arthur Eddington took photographs of stars visible near the dimmed Sun. These scientists compared these to other photographs taken at night when the light of those same stars did not pass close to the Sun before reaching Earth. These data confirmed Einstein’s prediction of the starlight’s deflection. The Sun changed the path of nearby starlight as the theory of general relativity predicted, providing confirmation of the theory. When the press reported that a key prediction of Einstein’s theory had been borne out by observation, Einstein became a famous public figure.

Eddington’s test of Einstein’s new theory was a crucial experiment, an experiment that decisively adjudicates between two hypotheses. This kind of dramatic experimental result is exciting, but even crucial experiments do not yield scientific knowledge.

 As we have seen, even well‐designed experiments face numerous potential sources of error: unidentified confounding variables, reliance on background knowledge that might be wrong and techniques or instruments that might not work as intended, and unidentified alternative hypotheses that might account for the data rather than the hypothesis under investigation. These potential sources of error cannot be eliminated with one single experiment, and so science has developed experimental techniques to minimize the risks of these errors.

One is replication. Replication is performing the original experiment again—often with some modification to its design—in order to check whether the result remains the same. If, for example, Newton’s two‐prism experiment is replicated by different people, using different prisms, in different places and at different times, and they also observe the spectrum of light recombining into white light, this additionally supports Newton’s hypothesis that white light contains a spectrum of color. This shows that no oddities of Newton’s equipment or circumstances is responsible for the result, increasing internal experimental validity. Replication attempts that vary features of the experimental design—the experimental subjects or subject selection, the types of instruments or surveys used, and so on—can increase external experimental validity.

The replicability of experimental outcomes is an important ingredient of science, so much so that a persistent failure to replicate experimental findings may undermine a scientific field’s credibility. If some experimental result cannot be replicated—if different scientists follow similar experimental procedures but do not get the same result—then the original experimental result might be a fluke, or it might be due to some confounding variable in the experimental setup that the scientists haven’t yet identified.

For example, it has been suggested that the field of social psychology faces a crisis in replicability, where different research groups have tried but failed to replicate some classic experimental results. Thus, we shouldn’t put too much stock in those findings, unless this failure in experimental replicability is resolved.

##### Box 3.2 The replication crisis

Nobel Prize winner Daniel Kahneman wrote an alarmed open letter to social psychologists in 2012. He pointed out that prominent results in priming research, which is the study of how subtle cues can unconsciously influence social behavior, failed to replicate. Kahneman claimed that this field had become “the poster child for doubts about the integrity of psychological research.” This was the alarm bell that psychology was probably suffering from a replication crisis: original experimental findings widely cited by other researchers and taught to students as “facts” failed to replicate when similar experiments were performed again by other researchers. This was worrisome, as the trustworthiness of science partly depends on the idea that studies repeated under similar conditions will produce similar results.

Further, it’s not only research in social priming that suffers from problems in replicability. Important published results in the psychological, social, behavioral, and biomedical sciences have also failed to replicate. Researchers in these fields have started to discuss various potential reasons for the crisis, including sloppy experimental design and statistical analysis, publication bias, and outright fraud. And various remedies have been proposed too, such as reforms in statistical analysis, changed publication practices, more careful and powerful study designs, and—more generally—a call for open science, whereby all research practices and data are made freely available for anyone to scrutinize or use.

The importance of replication fits with the idea that science is essentially a collaborative, social venture. Gaining scientific knowledge via experimentation is generally more complicated and slower than a single dramatic experiment. This also means that scientific knowledge can go in unexpected directions. A surprising finding that upends something we thought we understood might be right around the corner.

#### Calibration

To persuade other members of the Royal Society that his hypothesis about light was true, Newton had to show that his prisms were reliable scientific instruments. For this reason, many of Newton’s experiments aimed at testing how prisms with different shapes and composition affected the light spectrum produced. Supported by Newton’s extensive data and theory of light, prisms became accepted scientific instruments.

As this illustrates, experiments also can be used to evaluate whether scientific instruments function as intended and to calibrate scientific instruments. Calibration, comparing the measurements of one instrument with those of another to check the instrument’s accuracy and adjusting it if needed, was introduced in section 3.2. This is required not just for technical apparatus like prisms and thermometers but also for surveys or questionnaires used with human subjects. Any instrument for data collection must be calibrated using known measurements before it can be used in an experiment with uncertain results.

Brain imaging techniques are a nice illustration of using experiments to establish the function of an instrument and to calibrate it for data collection. fMRI machines track blood flow in the brain. They do not directly measure neural activity, but that is what the scientists employing these machines want to assess. Neuroscientists use data about blood flow to track neural activity because they know that greater neural activity requires more energy, which requires increased metabolism, which uses more oxygen, and oxygen is delivered by blood flow. The confidence that blood flow in a brain region is a reliable measure of neural activity is confirmed by experimental findings concerning brain metabolism and the relationship between different brain areas and functions. Experiments have been run over decades to additionally develop fMRI techniques and to improve their calibration as a tool to study neural activity.

Calibration requires establishing measurement standards, or rules to regulate the use of quantity concepts and to create a meaningful scale to apply across instruments. Examples include the standard kilogram for weight or mass measurements and setting the freezing and boiling points of water at 0° C and 100° C, respectively, as temperature reference points. A standardized scale enables measurements to be compared over time and across instruments. This body of measurement data might then be used to construct more stable measurement scales and more accurate instruments.

Measurements can be based on the value of physical constants, or quantities that are believed to be universal and unchanging over time, and these are also determined experimentally. From 1889 until 2019, the standard kilogram was defined by a physical measurement standard—a physical prototype with a mass that was, by stipulation, exactly one kilogram. In 2019, the kilogram was redefined on the basis of the Planck constant, a quantity in quantum physics.

However, no scientific instrument is perfectly precise. In 2017, scientists at the National Institute of Standards and Technology (NIST) used a Kibble balance—an instrument that uses electric current to produce extremely accurate measurements of mass—to determine the most precise value yet of the Planck constant. Even after more than 10,000 measurements with this specialized instrument, a small degree of uncertainty about the exact value of the Planck constant remained. Future experiments that further refine the measurement of the Planck constant will in turn change (very slightly) how the mass of a kilogram is defined. (The value of the Planck constant is about 6.62607015 × 10−34 J/Hz if you were wondering.) Another physical constant measured experimentally is the speed of light in a vacuum. The measure of this constant has been refined from the 18th century through late 20th century, and it is used to define standard measures of both distance (the meter) and time (the second).

#### Exploratory experiments

In 1800, the British astronomer William Herschel used a telescope to observe sunspots, which are regions on the Sun that appear temporarily dark. Observing sunspots is hazardous for the eyes, and so he used colored glass filters to reduce the intensity of the rays. Herschel noticed that he could feel the Sun’s heat coming through the filters, and different filters seemed to differ in temperature. Since the filters were made of the same material, Herschel wondered whether the different colors of the filters might actually be responsible for the temperature differences. Notice that this wasn’t what Herschel had set out to investigate; sometimes experiments take us in unanticipated directions.

Herschel tested his hypothesis about a relationship between light’s color and temperature by directing sunlight through a prism to spread the spectral colors, as Newton had. Then he measured each color—red, orange, yellow, green, blue, indigo, violet—with a mercury thermometer. He also measured the ambient temperature in the room in order to have a baseline temperature to compare with the temperature measurements of the light. This setup yielded data in the form of measured values of color and measured values of temperature, which could be used as evidence to evaluate the hypothesis that different colors of light differ also in temperature. The evidence confirmed this hypothesis: Herschel found that the temperatures increased incrementally from the “cool” colors like blue to the “warm” colors like orange.

Another of Herschel’s observations in this experiment introduced a new question about light. Herschel also measured the temperature of the air just beyond the beam of red light, outside the edge of the spectrum created by sunlight through the prism, where no light was visible. His hypothesis was that this temperature would be the same as the ambient temperature in the room, since it was beyond the edge of the light spectrum. To his surprise, the temperature at that location was much warmer than the ambient room temperature, even higher than any of the temperature measurements for the light spectrum. How could that be?

Herschel’s observation immediately led to a new hypothesis: invisible, hot light exists just beyond the red part of the visible spectrum. This hypothesis—anticipated by the French physicist Émilie du Châtelet almost 65 years earlier—explained the observation that the temperature continued to increase beyond the edge of red light. Later observations confirmed this hypothesis, and we now accept the existence of this hot, invisible light. It’s called infrared light.

A further role of experiments, beyond hypothesis-testing, replication, and calibration, is exploratory. Exploratory experiments may not rely on existing theory and are Herschel’s experimental setup to test the relationship between color and temperature of light not aimed to test a specific hypothesis; instead, they are used to gather data to suggest novel hypotheses or to assess whether a poorly understood phenomenon actually exists.

Herschel’s work on the relationship between heat and light did not rely on a particular theory or a hypothesis about that relationship. When, while investigating sunspots, he discovered that red light is warmer, Herschel surmised that the light spectrum is made of both heat and colors. This idea was on the right track, but it was not until James Maxwell’s theory of electromagnetic radiation that Herschel’s observations could be adequately explained and his work vindicated.

##### EXERCISES

3.19 Recall: Define crucial experiment and describe three limitations of crucial experiments’ decisiveness.

3.20 Recall: Describe why replication is important and how replication can improve internal and external experimental validity.

3.21 Recall: Describe how calibration relies on measurement, and what role experiments play in measurement.

3.22 Think: Briefly describe three roles for experiments other than testing hypotheses, and give an example of each. Then discuss how each of these might relate indirectly to testing hypotheses.

3.23 Think: Describe how exploratory experiments differ from experiments to test hypotheses. Consider the important features of experimental design. What are some drawbacks to exploratory experiments, related to expectations, extraneous variables, and experimental design?

3.24 Apply: Before Ibn al-Haytham’s work, some thought that vision involved light shining out of the eye, coming into contact with objects, and thereby making them visible. This was known as the emission theory of vision. Ibn al-Haytham set up the following experiment to test the emission theory. He stood in a dark room with a small hole in one wall. Outside of the room, he hung two lanterns at different heights. He found that the light from each lantern illuminated a different spot in the room. For each, there was a straight line between the lighted spot, the hole in the wall, and one of the lanterns. Covering a lantern caused the spot it illuminated to darken, and exposing the lantern caused the spot to reappear.

1. What is the independent variable and what is the dependent variable?
2. How did Ibn al-Haytham control extraneous variables?
3. How did the experimental result provide evidence against the emission theory?
4. Describe one way in which the emission theory might be adapted to account for the data (but still remain an emission theory of vision).
5. Describe a new hypothesis you can formulate based on the results of Ibn al-Haytham’s experiment.

##### FURTHER READING

For an introduction to the philosophy of experiments with a focus on the natural sciences, see Hacking, I. (1983). *Representing and intervening: Introductory topics in the philosophy of natural science*. Cambridge University Press.

For more on the experimental approach in the social sciences with a focus on economics, see Guala, F. (2005). *The methodology of experimental economics*. Cambridge University Press.

For a case study on the role of instruments and measurements in experiments and studies, see Chang, H. (2004). *Inventing temperature: Measurement and scientific progress*. Oxford University Press.

For a recent perspective on replicability and the so-called replicability crisis, see Romero, F. (2019). *Philosophy of science and the replicability crisis*. Philosophy Compass, 14 (11), 1–14.